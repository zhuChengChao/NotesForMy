# 面经：5-并发编程

### 线程与进程概述 :exclamation::exclamation::exclamation:

**总结**：**进程是操作系统进行资源分配和调度的最小单位，而线程是 CPU 分派和调度的最小单位**；

**进程**：

* 进程是程序的⼀次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行⼀个程序即是⼀个进程从创建，运行到消亡的过程。 
* 在 Java 中，当我们启动 main 函数时其实就是启动了⼀个 JVM 的进程，而 main 函数所在的线程就是这个进程中的⼀个线程，也称主线程。 

**线程：**

线程是进程的一个实体，也是 **CPU 调度和分派的基本单位**，它是比进程更小的能独立运行的基本单位，有时又被称为轻权进程或轻量级进程。

> 与进程不同的是同类的多个线程共享进程的堆和方法区资源，但**每个线程有自己的程序计数器、 虚拟机栈和本地方法栈**，所以系统在产生⼀个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 

**二者对比**

* **进程是操作系统进行资源分配和调度的最小单位，而线程是 CPU 分派和调度的最小单位**；

- 进程基本上相互独立的，进程间不会相互影响；而线程存在于进程内，是进程的一个子集，一个线程挂掉将可能导致整个进程挂掉；
- 不同进程地址空间相互独立；而同一进程内的线程共享进程内部的地址空间。
- 进程间通信较为复杂；线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一个共享变量
  - 同一台计算机的进程通信称为 IPC（Inter-process communication）
  - 不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP
- 创建进程或撤销进程，系统都要为之分配或回收资源，操作系统开销远大于创建或撤销线程时的开销；
- 线程更轻量，线程上下文切换成本一般上要比进程上下文切换低

### 线程与进程的异同 :exclamation:

**从 JVM 角度说进程和线程之间的关系** 

<img src="https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809280.PNG" alt="JVM角度分析线程和进程的关系" style="zoom: 67%;" />

从上图可以看出：

* ⼀个进程中可以有多个线程；
* 多个线程共享进程的堆和方法区（JDK1.8 之后的元空间）资源；
* 但是每个线程有自己的程序计数器、 虚拟机栈 和 本地方法栈。 

**总结**： 

**线程是进程划分成的更小的运行单位。**线程和进程最大的不同在于基本上各进程是独立的，而各线程则不⼀定，因为同⼀进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。

### 程序计数器 & 虚拟机栈 & 本地方法栈

**程序计数器为什么是私有的?** 

程序计数器主要有下面两个作用：

1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 

> 需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下⼀条指令的地址。 

所以，程序计数器私有主要是为了**线程切换后能恢复到正确的执行位置**。 

**虚拟机栈和本地方法栈为什么是私有的?** 

* **虚拟机栈**： 每个 Java 方法在执行的同时会创建⼀个**栈帧**用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着⼀个栈帧在 Java 虚拟机栈中入栈和出栈的过程。
* **本地方法栈**： 和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务**。 在 HotSpot 虚拟机中和 Java 虚拟机栈合⼆为⼀。 

所以，为了**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的。 

**⼀句话简单了解堆和方法区**

堆和方法区是所有线程共享的资源；

* 其中堆是进程中最大的⼀块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)；
* 方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 

### 并发与并行的区别

**并发**：

* 是同一时间应对（dealing with）多件事情的能力
* 同⼀时间段，多个任务都在执行 (单位时间内不⼀定同时执行)； 

**并行**：

* 并行（parallel）是同一时间动手做（doing）多件事情的能力
* 单位时间内，多个任务同时执行。 

单核 CPU 下：线程实际还是 **串行执行** 的。

操作系统中有一个组件叫做**任务调度器**，将 CPU 的时间片（windows下时间片最小约为 15 毫秒）分给不同的程序使用，只是由于 CPU 在线程间（时间片很短）的切换非常快，人类感觉是同时运行的。总结为一句话就是： **微观串行，宏观并行**。

一般会将这种线程轮流使用 CPU 的做法称为**并发：concurrent**

**多核CPU下**：每个核（core）都可以调度运行线程，这时候线程可以是并行的。

### 守护线程和用户线程的区别

Java 中的线程分为两种：

- 守护线程（Deamon）
- 用户线程（User）

任何线程都可以设置为守护线程和用户线程，通过方法：

`Thread.setDeamon(boolean);` 为 `true` 则把该线程设置为守护线程，反之则为用户线程。

`Thread.setDeamon()`必须在 `Thread.start()` 之前调用，否则运行时会抛出异常：`IllegalThreadStateException `。

**两者的区别**：

默认情况下，Java 进程需要等待所有线程都运行结束，才会结束。有一种特殊的线程叫做**守护线程，只要其它非守护线程运行结束了，即使守护线程的代码没有执行完，也会强制结束**。

比如：JVM 的垃圾回收线程就是守护线程，Finalizer 也是守护线程。

### Java 中用到的线程调度算法

计算机通常只有固定几个 CPU 核心数，在任意时刻只能执行一条机器指令，每个线程只有获得 CPU 的使用权才能执行指令。所谓多线程的并发运行，其实是指从宏观上看，各个线程轮流获得 CPU 的使用权，分别执行各自的任务。在运行池中，会有多个处于就绪状态的线程在等待 CPU，**JAVA 虚拟机的一项任务就是负责线程的调度**，线程调度是指按照特定机制为多个线程分配 CPU 的使用权。

有两种调度模型：**分时调度模型**和**抢占式调度模型**。

**分时调度模型**：是指让所有的线程**轮流获得 CPU 的使用权**，并且平均分配每个线程占用的 CPU 的时间片。

**抢占式调度模型**：是指优先让可运行池中优先级高的线程占用 CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用 CPU。处于运行状态的线程会一直运行，直至它不得不放弃 CPU。

### 创建线程的方式 :exclamation:

**方式总结：**

1. 继承 Thread 类 / 直接用 Thread 类进行创建
2. 使用 Runnable 接口 配合 Thread
3. FutureTask 配合 Thread
4. 通过线程池创建

**方式1：直接使用 Thread 类创建**

```java
// 创建线程对象
Thread thread = new Thread(){
    // 重写run方法   
    @Override
    public void run(){
        // 要执行的任务
    }
};
// 启动线程
thread.start();
```

**方式2：使用 Runnable 接口 + Thread**

把 『线程』和『任务』（要执行的代码）分开

- Thread 代表线程
- Runnable 可运行的任务（线程要执行的代码）

```java
Runnable runnable = new Runnable() {
    @Override
    public void run() {
        // 要执行的任务
    }
};
// 创建线程对象
Thread thread = new Thread(runnable);
// 启动线程
thread.start();

// 用lambda 精简代码 
Runnable runnable = () -> {
    // 要执行的任务
};
```

> **Thread 与 Runnable 的关系：**分析 Thread 的源码:
>
> ```java
>// 线程thread类中有一个成员属性
> private Runnable target;
> 
> // 1,构造函数
> public Thread(Runnable target) {
>     init(null, target, "Thread-" + nextThreadNum(), 0);
> }
>    // 2 init方法中继续传递Runnable
> private void init(ThreadGroup g, Runnable target, String name, long stackSize) {
>     init(g, target, name, stackSize, null, true);
> }
>    private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) {
>     // ...
>     // thread类中的成员属性target指向了Runnable对象
>        this.target = target;
>        // ...
>    }
>    
> // 最终的run方法，即调用了run方法
> @Override
> public void run() {
>     if (target != null) {
>         target.run();
>        }
>    }
>    ```

**方式1和方式2的小结**：

- 方法1 是把线程和任务合并在了一起，方法2 是把线程和任务分开了
- 用 Runnable 更容易与线程池等高级 API 配合
- 用 Runnable 让任务类脱离了 Thread 继承体系，更灵活

**方式3：FutureTask 配合 Thread**

FutureTask 能够接收 Callable 类型的参数，用来处理有返回结果的情况

```java
// 创建任务对象
FutureTask<Integer> task = new FutureTask<>(new Callable<Integer>() {
    @Override
    public Integer call() throws Exception {
        LoggerUtils.LOGGER.debug("FutureTask+Callable");
        Thread.sleep(2000);
        return 100;
    }
});

// 参数1：任务对象; 参数2：线程名字，推荐
new Thread(task, "t3").start();

// 主线程阻塞，同步等待 task 执行完毕的结果
Integer result = task.get();
LoggerUtils.LOGGER.debug("result:{}", result);

// 输出结果：
// 11:24:55.097 cn.util.LoggerUtils [t3] - FutureTask+Callable
// 11:24:57.102 cn.util.LoggerUtils [main] - result:100
```

**Runnable和Callable的区别**：

- **重写方法不同**：Callable规定（重写）的方法是`call()`，Runnable规定（重写）的方法是`run()`。
- **返回值**：Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。
- **异常**：call方法可以抛出异常；run方法不可以，只能在内部消化（导致线程会吞掉异常）。
- 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。

**方法4：通过线程池创建**

> 不在此展开

### Thread类中的常见方法:exclamation:

| 方法名             | 功能说明                                                     | 注意                                                         |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `start()`          | 启动一个新线程，在新的线程运行 run 方法中的代码              | start 方法只是让线程进入就绪，里面代码不一定立刻运行(CPU的时间片还没分给它)<br />每个线程对象的 start 方法只能调用一次，如果调用了多次会出现 `IllegalThreadStateException`异常 |
| `run()`            | 新线程启动后会调用的方法                                     | 如果在构造 Thread 对象时传递了 Runnable 参数，则线程启动后会调用 Runnable 中的 run 方法，否则默认不执行任何操作；<br />但可以创建 Thread 的子类对象， 来覆盖默认行为 |
| `join()`           | 等待线程运行结束                                             | 在调用的线程中，等待调用join的线程结束后，继续执行后面的语句； <br />即A线程中调用 `B.join()`，则A线程阻塞到B线程执行完毕时继续执行 |
| `join(long n)`     | 等待线程运行结束，最多等待 n 毫秒                            |                                                              |
| `getId()`          | 获取线程长整型的 id                                          | id 唯一                                                      |
| `getName()`        | 获取线程名                                                   |                                                              |
| `setName(String)`  | 修改线程名                                                   |                                                              |
| `getPriority()`    | 获取线程优先级                                               |                                                              |
| `setPriority(int)` | 修改线程优先级                                               | Java 中规定线程优先级是1~10 的整数，较大的优先级能提高该线程被 CPU 调度的机率 |
| `getState()`       | 获取线程状态                                                 | Java 中线程状态是用 6 个 enum 表示，分别为： <br />NEW, RUNNABLE, BLOCKED, <br />WAITING, TIMED_WAITING, TERMINATED |
| `isAlive()`        | 线程是否存活(还没有运行完毕)                                 |                                                              |
| `interrupt()`      | 打断线程<br />调用该方法的线程的状态为将被置为”中断”状态<br />**注意：线程中断仅仅是设置线程的中断状态位，不会停止线程** | 如果被打断线程正在 sleep，wait，join 会导致被打断的线程抛出 InterruptedException，**并清除打断标记**； <br />如果打断的正在运行的线程，则**会设置打断标记**； <br />park 的线程被打断，也**会设置打断标记** |
| `isInterrupted()`  | 判断是否被打断                                               | **不会清除打断标记**                                         |
| `interrupted()`    | 判断当前线程是否被打断                                       | **调用后会清除打断标记**<br />**static 方法**                |
| `currentThread()`  | 获取当前正在执行的线程                                       | **static 方法**：`Thread.currentThread().getName()`          |
| `sleep(long n)`    | 让当前执行的线程休眠n毫秒，休眠时让出 CPU的时间片给其它线程  | **static 方法**                                              |
| `yield()`          | 提示线程调度器让出当前线程对CPU的使用                        | 主要是为了测试和调试<br />调用 yield 会让当前线程从 Running 进入 Runnable 就绪状态，然后调度执行其它线程<br />具体的实现依赖于操作系统的任务调度器<br />**static 方法** |
| `holdsLock()`      | 判断当前线程中是否有某个对象的锁                             | `public static native boolean holdsLock(Object obj);`<br />**static 方法** |

**问题1：为什么 `sleep(long n)` 和 `yield()`是静态的？**

Thread 类的 `sleep()` 和 `yield()` 方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。

**问题2：关于 `interrupt` & `isInterrupted()` & `interrupted()` 小总结**

* `interrupt()`
  * 用于打断线程，调用该方法的线程的状态为将被置为”中断”状态，**但是：线程中断仅仅是置线程的中断状态位，不会停止线程**
  * 需要用户自己去监视线程的状态为并做处理，通过 isInterrupted / interrupted 方法
  * 如果被打断线程正在 sleep，wait，join 会导致被打断的线程抛出 InterruptedException，**并清除打断标记**；
  * 如果打断的正在运行的线程，则**会设置打断标记**；
  * park 的线程被打断，也**会设置打断标记**
* `isInterrupted()`：判断是否被打断，**不会清除打断标记**
* `interrupted()`：判断当前线程是否被打断，**调用后会清除打断标记**

### 多线程的优点与缺点 :exclamation:

**多线程的优点：**

1. **发挥多核CPU的优势**

   多线程，可以真正发挥出多核CPU的优势来，**达到充分利用CPU的目的**，采用多线程的方式去同时完成几件事情而不互相干扰。

   > 多核 CPU 可以并行跑多个线程，但能否提高程序运行效率还是要分情况的:
   >
   > 1. 有些任务，经过精心设计，将任务拆分，并行执行，当然可以提高程序的运行效率。
   > 2. 也不是所有计算任务都能拆分，都需要拆分，任务的目的如果不同，谈拆分和效率没啥意义。

2. **防止阻塞**

   从程序运行效率的角度来看，单核CPU不但不会发挥出多线程的优势，反而会因为在单核CPU上运行多线程导致线程上下文的切换，而降低程序整体的效率。

   **但是单核CPU我们还是要应用多线程，就是为了防止阻塞。**试想，如果单核CPU使用单线程，那么只要这个线程阻塞了，比方说远程读取某个数据吧，对端迟迟未返回又没有设置超时时间，那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题，多条线程同时运行，哪怕一条线程的代码执行读取数据阻塞，也不会影响其它任务的执行。

3. **便于建模**

   这是另外一个没有这么明显的优点了。假设有一个大的任务A，单线程编程，那么就要考虑很多，建立整个程序模型比较麻烦。但是如果把这个大的任务A分解成几个小任务，任务B、任务C、任务D，分别建立程序模型，并通过多线程分别运行这几个任务，那就简单很多了。

**多线程的缺点：**

1. 大量的线程降低代码的可读性；
2. 更多的线程需要更多的内存空间；
3. 当多个线程对同一个资源出现争夺时候要注意线程安全的问题。

### 线程安全和线程不安全 :exclamation:

**通俗的说：加锁的就是是线程安全的，不加锁的就是是线程不安全的**

**线程安全**: 就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问，直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。

> 例如：一个线程安全的计数器类的同一个实例对象，在被多个线程使用的情况下也不会出现计算失误。
>
> 很显然你可以将**集合类分成两组，线程安全和非线程安全的**。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。

**线程不安全**：就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。

**线程安全问题都是由全局变量及静态变量引起的。**若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

**Java中保障线程安全的方式有**：同步机制（Join、Future等）、使用原子类、加锁、使用 volatile、使用不可变类、使用线程安全类。

**成员变量和静态变量是否线程安全？**

- 如果它们没有共享，则线程安全
- 如果它们被共享了，根据它们的状态是否能够改变，又分两种情况
  - 如果只有读操作，则线程安全
  - 如果有读写操作，则这段代码是临界区，需要考虑线程安全

**局部变量是否线程安全？**

- 局部变量是线程安全的
- 但局部变量引用的对象则未必是线程安全的
  - 如果该对象没有逃离方法的作用访问，它是线程安全的
  - 如果该对象逃离方法的作用范围，需要考虑线程安全

### 临界区&竞态条件

**临界区 Critical Section**

- 一个程序运行多个线程本身是没有问题的
- 问题出在多个线程访问**共享资源**
  - 多个线程读共享资源其实也没有问题
  - 在多个线程对共享资源读写操作时发生**指令交错**，就会出现问题
- 一段代码块内如果存在对共享资源的多线程读写操作，称这段代码块为**临界区**

例如，下面代码中的临界区

```java
static int counter = 0;

static void increment(){
    counter ++;
}
static void decrement(){
    counter --;
}
```

**竞态条件（Race Condition）**

多个线程在临界区内执行，由于代码的**执行序列不同**而导致结果无法预测，称之为发生了**竞态条件**

### 多线程同步和互斥

**线程同步**：是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。

> 线程同步可以通过：
>
> 1. join 实现
> 2. Future 实现
> 3. BlockingQueue 实现

**线程互斥**：是指对于共享的进程系统资源，在各单个线程访问时的**排它性**。当有若干个线程都要使用某一共享资源时，**任何时刻最多只允许一个线程去使用**，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。

> 悲观互斥：通过锁
>
> 乐观重试：通过CAS

### 线程的状态:exclamation::exclamation:

> **五种状态**：这是从 **操作系统** 层面来描述的
>
> ![线程的5种状态](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809860.PNG)
>
> - 『初始状态』仅是在语言层面创建了线程对象，还未与操作系统线程关联
> - 『可运行状态』（就绪状态）指该线程已经被创建（与操作系统线程关联），可以由 CPU 调度执行
> - 『运行状态』指获取了 CPU 时间片运行中的状态
>   - 而当 CPU 时间片用完，会从『运行状态』转换至『可运行状态』，会导致线程的上下文切换
> - 『阻塞状态』
>   - 如果调用了阻塞 API，如 BIO 读写文件，这时该线程实际不会用到 CPU，会导致线程上下文切换，进入『阻塞状态』
>   - 等 BIO 操作完毕，会由操作系统唤醒阻塞的线程，转换至『可运行状态』
>   - 与『可运行状态』的区别是，对『阻塞状态』的线程来说只要它们一直不唤醒，调度器就一直不会考虑调度它们
> - 『终止状态』表示线程已经执行完毕，生命周期已经结束，不会再转换为其它状态

**六种状态**：**这是从 Java API 层面来描述的**

![线程的6种状态](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809323.PNG)

根据 `Thread.State` 枚举，分为六种状态

```java
Thread.State.NEW;
Thread.State.RUNNABLE;
Thread.State.WAITING;
Thread.State.TIMED_WAITING;
Thread.State.BLOCKED;
Thread.State.TERMINATED;
```

- `NEW` 线程刚被创建，但是还没有调用 `start()` 方法

- `RUNNABLE` 当调用了 `start()` 方法之后，线程即进入`RUNNABLE`状态。

  > 注意，Java API 层面的 `RUNNABLE` 状态涵盖了操作系统层面的『可运行状态』、『运行状态』和『阻塞状态』（由于 **BIO 导致的线程阻塞**，在 Java 里无法区分，仍然认为是可运行）

- `BLOCKED` ， `WAITING` ， `TIMED_WAITING` 都是 Java API 层面对『阻塞状态』的细分

  * `BLOCKED`：阻塞状态，**表示线程阻塞于锁**
  * `WAITING`：等待状态，表示线程进入等待状态，进入等待状态表示当前线程需要等待其他线程做出一些特定动作（通知或中断）
  * `TIMED_WAITING`：超时等待状态，该状态不同于`WAITING`，它是可以在指定的时间自行返回的

- `TERMINATED` 终止状态，表示当前线程已经执行完毕

### 线程状态转换 :exclamation:

![线程的6种状态](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251818692.PNG)

**假设有线程 Thread t**

由上图可以看出：线程创建之后它将处于 NEW 状态，调用 `start()` 方法后开始运行，线程这时候处于 RUNABLE 状态。可运行状态的线程获得了 CPU 时间片后就处于 RUNNING 状态。

当线程执行 `wait()` 方法之后，线程进入 WAITING 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING 状态相当于在等待状态的基础上增加了超时限制，比如通过 `sleep(long millis)`方法或 `wait(long millis)`方法可以将 Java 线程置于 TIMED_WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED 状态。线程在执行 Runnable 的 `run()` 方法之后将会进入到 TERMINATED 状态。  

**具体说明：**

**情况 1 `NEW --> RUNNABLE`**

当调用 `t.start()` 方法时，由 `NEW --> RUNNABLE`

**情况 2 `RUNNABLE <--> WAITING`**

t 线程用 `synchronized(obj)` 获取了对象锁后

- 调用 `obj.wait()` 方法时，t 线程从 `RUNNABLE --> WAITING`
- 调用 `obj.notify()` ， `obj.notifyAll()` ， `t.interrupt()` 时
  - 竞争锁成功，t 线程从 `WAITING --> RUNNABLE`
  - 竞争锁失败，t 线程从 `WAITING --> BLOCKED`

> 这些 wait / notify / notifyAll 都是要获得锁才能操作的，即需要在 synchronize 代码块内操作

**情况 3 `RUNNABLE <--> WAITING`**

- 当前线程调用 `t.join()` 方法时，当前线程从 `RUNNABLE --> WAITING`
  - 注意是当前线程在 t 线程对象的监视器上等待，即：调用 join 的线程等待 t线程 执行完成
- t 线程运行结束，或调用了当前线程的 `interrupt()` 时，当前线程从 `WAITING --> RUNNABLE`

**情况 4 `RUNNABLE <--> WAITING`**

- 当前线程调用 `LockSupport.park()` 方法会让当前线程从 `RUNNABLE --> WAITING`
- 调用 `LockSupport.unpark(目标线程)` 或调用了线程的 `interrupt()` ，会让目标线程从 `WAITING -->RUNNABLE`

**情况 5 `RUNNABLE <--> TIMED_WAITING`**

t 线程用 `synchronized(obj)` 获取了对象锁后

- 调用 `obj.wait(long n)` 方法时，t 线程从 `RUNNABLE --> TIMED_WAITING`
- t 线程等待时间超过了 n 毫秒，或调用 `obj.notify()` ， `obj.notifyAll()` ， `t.interrupt()` 时
  - 竞争锁成功，t 线程从 `TIMED_WAITING --> RUNNABLE`
  - 竞争锁失败，t 线程从 `TIMED_WAITING --> BLOCKED`

**情况 6 `RUNNABLE <--> TIMED_WAITING`**

- 当前线程调用 `t.join(long n)` 方法时，当前线程从 `RUNNABLE --> TIMED_WAITING`
  - 注意是当前线程在 t 线程对象的监视器上等待，即：调用join的线程等待t线程执行完成
- 当前线程等待时间超过了 n 毫秒，或 t线程运行结束，或调用了当前线程的 `interrupt()` 时，当前线程从`TIMED_WAITING --> RUNNABLE`

**情况 7 `RUNNABLE <--> TIMED_WAITING`**

- 当前线程调用 `Thread.sleep(long n)` ，当前线程从 `RUNNABLE --> TIMED_WAITING`
- 当前线程等待时间超过了 n 毫秒，当前线程从 `TIMED_WAITING --> RUNNABLE`

**情况 8 `RUNNABLE <--> TIMED_WAITING`**

- 当前线程调用 `LockSupport.parkNanos(long nanos)` 或 `LockSupport.parkUntil(long millis)` 时，当前线程从 `RUNNABLE --> TIMED_WAITING`
- 调用 `LockSupport.unpark(目标线程)` 或调用了线程的 `interrupt() `，或是等待超时，会让目标线程从`TIMED_WAITING--> RUNNABLE`

**情况 9 `RUNNABLE <--> BLOCKED`**

- t 线程用 `synchronized(obj)` 获取了对象锁时如果竞争失败，从 `RUNNABLE --> BLOCKED`
- 持 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有 `BLOCKED` 的线程重新竞争，如果其中 t 线程竞争成功，从 `BLOCKED --> RUNNABLE` ，其它失败的线程仍然 `BLOCKED`

**情况 10 `RUNNABLE <--> TERMINATED`**

当前线程所有代码运行完毕，进入 `TERMINATED`

### 多线程的上下文切换 :exclamation:

**线程上下文切换（Thread Context Switch）**

因为以下一些原因导致 CPU 不再执行当前的线程，转而执行另一个线程的代码

- 线程的 CPU 时间片用完
- 垃圾回收
- 有更高优先级的线程需要运行
- 线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法

当线程上下文切换发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，Java 中对应的概念就是程序计数器（Program Counter Register），它的作用是记住下一条 JVM 指令的执行地址，程序计数器是线程私有的

- 状态包括：程序计数器、虚拟机栈中每个栈帧的信息，如局部变量、操作数栈、返回地址等

上下文切换频繁发生会影响性能

### 死锁&活锁&饥饿的区别 :exclamation:

**死锁**：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。

**产生死锁的必要条件**：

1. **互斥条件**：所谓互斥就是进程在某一时间内独占资源。
2. **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. **不可剥夺条件**：线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. **循环等待条件**：若干进程之间形成一种头尾相接的循环等待资源关系。

> **如何避免死锁**：
>
> 我上面说了产生死锁的四个必要条件，为了避免死锁，我们只要破坏产生死锁的四个条件中的其中⼀个就可以了。现在我们来挨个分析⼀下：
>
> 1. 破坏互斥条件 ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
>
> 2. 破坏请求与保持条件 ：⼀次性申请所有的资源。
>
> 3. 破坏不可剥夺条件 ：占用部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
>
> 4. 破坏循环等待条件 ：靠按序申请资源来预防。按某⼀顺序申请资源，释放资源则反序释放。

**活锁**：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。

**活锁和死锁的区别**：

- 处于活锁的实体是在不断的改变状态，所谓的“活”；
- 而处于死锁的实体表现为等待；
- **活锁有可能自行解开，死锁则不能**。

**饥饿**：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。

**Java 中导致饥饿的原因**：

1. 高优先级线程吞噬所有的低优先级线程的 CPU 时间。
2. 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问（就是拿不到锁）。
3. 线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的 wait 方法)，因为其他线程总是被持续地获得唤醒。

### `sleep()` 和 `wait()` 的异同

* 两者最主要的区别在于：**sleep 方法没有释放锁，而 wait 方法释放了锁** 。
* 两者都可以暂停线程的执行。
* wait 通常被用于线程间交互/通信， sleep 通常被用于暂停执行。
* wait 方法被调用后，线程不会自动苏醒，需要别的线程调用同⼀个对象上的 `notify()` 或者 `notifyAll()` 方法。 sleep 方法执行完成后，线程会自动苏醒。当然前者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。 

### `start()` 和 `run()` 的区别

- 直接调用 run 是在主线程中执行了 run，**没有启动新的线程**
- 使用 start 是启动新的线程，通过新的线程间接执行 run 中的代码

### synchronized 关键字概述 :exclamation::exclamation::exclamation:

synchronized 关键字解决的是**多个线程之间访问资源的同步性**；

synchronized 关键字可以**保证被它修饰的方法或者代码块在任意时刻只能有⼀个线程在执行**。 

> 另外，在 Java 早期版本中， synchronized 属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的， Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒⼀个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较⻓的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。
>
> 庆幸的是在 JDK 6 之后 Java 官方对从 JVM 层面对 synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。 JDK1.6 对锁的实现引入了大量的优化，如**自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁**等技术来减少锁操作的开销。 （后续有讲）

**synchronized 关键字的使用方式**

* **修饰实例方法**：作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁

* **修饰静态方法**：也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何⼀个实例对象，是类成员（ static 表明这是该类的⼀个静态资源，不管 new 了多少个对象，只有⼀份）。

  > 所以如果⼀个 线程A 调用⼀个实例对象的非静态 synchronized 方法，而 线程B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象， 因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。

* **修饰代码块**：指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 

**总结**： 

* 类锁：synchronized 关键字加到 **static 静态方法** 和 **synchronized(xxx.class)** 代码块上都是是给 Class 类上锁。 
* 对象锁：synchronized 关键字加到实例方法上是给对象实例上锁。

> 尽量不要使用 `synchronized(String对象)` 因为 JVM 中，字符串常量池具有缓存功能！ 

### synchronized 关键字的底层原理 :exclamation::exclamation:

synchronized 关键字底层原理属于 JVM 层面

**synchronized 同步语句块的情况：**

* 代码如下：

  ```java
  // Demo类中的代码
  static final Object lock = new Object();
  static int counter = 0;
  public static void main(String[] args) {
      // 代码块加锁
      synchronized (lock) {
          counter++;
      }
  }
  ```

  > 通过 JDK 自带的 javap 命令查看 Demo 类的相关字节码信息：首先切换到类的对应目录执行 `javac Demo.java` 命令生成编译后的 `Demo.class` ⽂件，然后执行 `javap -c -s -v -l Demo.class`

* 对应的字节码为：

  ```java
  public static void main(java.lang.String[]);
      descriptor: ([Ljava/lang/String;)V
      flags: ACC_PUBLIC, ACC_STATIC
      Code:
      	stack=2, locals=3, args_size=1
              0: getstatic #2 		 // <- lock引用 （synchronized开始）
              3: dup
              4: astore_1 			 // lock引用 -> slot 1
              5: monitorenter 		 // 将lock对象 MarkWord 置为 Monitor 指针☆
              6: getstatic #3			 // <- i
              9: iconst_1				 // 准备常数 1
              10: iadd 			     // +1
              11: putstatic #3  	     // -> i
              14: aload_1 		   	 // <- lock引用
              15: monitorexit          // 将lock对象 MarkWord 重置, 唤醒 EntryList☆
              16: goto 24
              19: astore_2 			 // e -> slot 2
              20: aload_1              // <- lock引用
              21: monitorexit          // 将 lock对象 MarkWord 重置, 唤醒 EntryList
              22: aload_2              // <- slot 2 (e)
              23: athrow               // throw e
              24: return
  ```

* 总结：**synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令**，依赖操作系统底层的互斥锁来实现
  * 其中 monitorenter 指令指向同步代码块的开始位置
  * 其中 monitorexit 指令则指明同步代码块的结束位置

  当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是+1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外⼀个线程释放为止。 

  > monitor 对象存在于每个 Java 对象的对象头中， synchronized 锁便是通过这种方式获取锁的，也是为什么 Java 中任意对象可以作为锁的原因

**synchronized 修饰方法的的情况**

* 代码为：

  ```java
  // Demo类中的代码
  public synchronized void method() {
      System.out.println("synchronized 方法");
  }
  ```

* 对应的字节码为：

  ```java
  public synchronized void method();
    descriptor: ()V
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED       // ☆这里多了一个同步标识☆
    Code:
      stack=2, locals=1, args_size=1
         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #3                  // String synchronized ?法
         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return
      LineNumberTable:
        line 10: 0
        line 11: 8
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0       9     0  this   LDemo;
  ```

* **总结**：synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确是 **ACC_SYNCHRONIZED 标识**，该标识指明了该方法是⼀个同步方法， JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别⼀个方法是否声明为同步方法，从而执行相应的同步调用。 

> 再进一步说明 synchronize 原理：（关于 Monitor ）
>
> [Java：并发笔记-03：Monitor 概念、synchronize原理](https://www.cnblogs.com/zhuchengchao/p/14491216.html)

### synchronized 优化 & 锁优化 :exclamation::exclamation:

JDK1.6 对锁的实现引入了大量的优化，如**偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化**等技术来减少锁操作的开销。 

锁主要存在四种状态从低到高依次是：**无锁状态→偏向锁状态→轻量级锁状态→重量级锁状态**，他们会随着竞争的激烈而逐渐升级。

* **自旋锁**：由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，**用户态和内核态的来回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环**，可以理解为就是啥也不干，防止从用户态转入内核态，自旋锁可以通过设置 `-XX:+UseSpining` 来开启，自旋的默认次数是10次，可以使用 `-XX:PreBlockSpin` 设置。
* **自适应锁**：自适应锁就是**自适应的自旋锁**，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。
* **锁消除**：锁消除指的是 JVM 检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。
* **锁粗化**：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。
* **轻量级锁**：JVM 的对象的对象头中包含有一些锁的标志位，代码进入同步块的时候，**JVM 将会使用 CAS 方式来尝试获取锁**，如果更新成功则会把对象头中的状态位标记为轻量级锁，如果更新失败，表明存在竞争情况，进入锁膨胀，将轻量级锁变为重量级锁的状态。
* **偏向锁**：当线程访问同步块获取锁时，会在**对象头和栈帧中的锁记录里存储偏向锁的线程ID，之后这个线程再次进入同步块时都不需要CAS来加锁和解锁**了，偏向锁会永远偏向第一个获得锁的线程，如果后续没有其他线程获得过这个锁，持有锁的线程就永远不需要进行同步，反之，当有其他线程竞争偏向锁时，持有偏向锁的线程就会释放偏向锁。可以用过设置 `-XX:+UseBiasedLocking` 开启偏向锁。

> 注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 
>
> 进一步了解可见：[Java：并发笔记-03：synchronize原理进阶](https://www.cnblogs.com/zhuchengchao/p/14491216.html)

### synchronized 和 ReentrantLock 的区别 :exclamation::exclamation::exclamation:

1. 相同点：**两者都是可重入锁**

   * 可重入锁就是**递归锁**：指的是同一线程外层函数获得锁之后，内层递归函数仍然能获取到该锁的代码，即在同一线程在外层方法获取锁的时候，在进入内层方法会自动获取锁
   * 也就是说：**线程可以进入任何一个它已经拥有的锁所同步的代码块**
   
2. synchronized 属于 **JVM 层面**，属于 Java 的关键字 / 而 ReentrantLock 依赖于 **Java API**

   * synchronized 是依赖于 JVM 实现的：monitorenter

     > 底层是通过 monitor 对象来完成，其实 wait/notify 等方法也依赖于 monitor 对象 只能在同步块或者方法中才能调用 wait/notify 等方法

   * ReentrantLock 是具体类（`java.util.concurrent.locks.ReentrantLock`）是 **API 层面**的锁，需要 `lock()` 和 `unlock()` 方法配合 `try catch finally` 语句来完成

3. **使用方式上：**

   * synchronized：不需要用户去手动释放锁，当 synchronized 代码执行后，**系统会自动让线程释放对锁**的占用
   * ReentrantLock：则需要用户去**手动释放锁**，若没有主动释放锁，就有可能出现死锁的现象，需要`lock()` 和 `unlock()` 配置 `try catch finally` 语句来完成

4. **等待是否可中断**

   - synchronized：**不可中断**，除非抛出异常或者正常运行完成
   - ReentrantLock：**可中断，也可以设置超时方法**
     - `lock.lockInterruptibly()` 放代码块中，调用`线程.interrupt()`方法**可以中断**
     - 设置**超时方法**，`lock.trylock(long timeout, TimeUnit unit)`

5. **加锁是否公平**

   - synchronized：非公平锁
   - ReentrantLock：默认非公平锁，构造函数可以传递 boolean 值，为 true 则为公平锁，false 为非公平锁

6. **锁是否可以定多个条件 Condition**

   - synchronized：没有，要么随机唤醒，要么全部唤醒
   - ReentrantLock：用来实现分组唤醒需要唤醒的线程，**可以精确唤醒**，而不是像 synchronized 那样，要么随机唤醒，要么全部唤醒

> 进一步：ReentrantLock 基于AQS(**AbstractQueuedSynchronizer 抽象队列同步器**)实现
>
> AQS 内部维护一个 state 状态位，尝试加锁的时候通过 CAS(CompareAndSwap) 修改值，如果成功设置为1，并且把当前线程赋值给相应变量，代表加锁成功，而其他的线程将会被阻塞进入阻塞队列，当获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把 state 重新置为 0，同时释放当前线程的占用。
>
> 传送门：[Java：AQS 小记-2(ReentrantLock)](https://www.cnblogs.com/zhuchengchao/p/14800883.html)

### 乐观锁和悲观锁 :exclamation:

**悲观锁**

* 悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。
* synchronize/ReentrantLock 是基于**悲观锁**的思想

**乐观锁**

* 最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，我吃亏点再**重试**呗。
* CAS 是基于**乐观锁**的思想，CAS 体现的是无锁并发、无阻塞并发，请仔细体会这两句话的意思
  - 因为没有使用 synchronize，所以线程不会陷入阻塞，这是效率提升的因素之一
  - 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 

> 在 Java中 `java.util.concurrent.atomic` 包下面的原子变量类就是使用了乐观锁的一种实现方式，即通过 CAS 实现无锁/无阻塞并发来保障线程安全

### 并发编程三要素

1. **原子性：**

   原子性指的是一个或者多个操作，要么全部执行并且在执行的过程中不被其他操作打断，要么就全部都不执行；

   其保证指令不会受到线程上下文切换的影响。

2. **可见性：**

   可见性指多个线程操作一个共享变量时，其中一个线程对变量进行修改后，其他线程可以立即看到修改的结果；

   保证指令不会受 CPU 缓存的影响。

3. **有序性：**

   即程序的执行顺序按照代码的先后顺序来执行；

   保证指令不会受 CPU 指令并行优化的影响。

### volatile 关键字的作用 :exclamation::exclamation:

volatile 保证**内存可见性**和**禁止指令重排**，但其**不能保证原子性**

> 在 JDK1.2 之前， Java 的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。
>
> 而在当前的 Java 内存模型下，**线程可以把变量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写**。这就可能造成⼀个线程在主存中修改了⼀个变量的值，而另外⼀个线程还继续使用它在寄存器中的变量值的拷贝，造成**数据的不⼀致**。 
>
> 要解决这个问题，就需要把变量**声明为 volatile**，这就指示 JVM，这个变量是不稳定的，每次**使用它都到主存中进行读取**。 

**内存可见性**：JMM 内存模型的可见性，指的是当主内存区域中的值被某个线程写入更改后，**其它线程会马上知晓更改后的值**，并重新得到更改后的值。

**指令重排**：关于进行指令重排序，需要满足以下两个条件：

1. 在单线程环境下不能改变程序运行的结果；
2. 存在数据依赖关系的不允许重排序

> 需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义

**volatile 通过内存屏障保证了内存的可见性与禁止了指令重排序，从而避免了多线程环境下程序出现乱序执行的现象**

首先了解一个概念，**内存屏障**（Memory Barrier）又称内存栅栏，是一个 CPU 指令，它的作用有两个：

- **保证特定操作的顺序：禁止了指令重排**
- **保证某些变量的内存可见性**（利用该特性实现 volatile 的内存可见性）

**而 volatile 的底层实现就是内存屏障**：

- 对 volatile 变量的写指令**后**会**加入写屏障**：
  - 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中
  - 屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 
- 对 volatile 变量的读指令**前**会**加入读屏障**：
  - 读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据 
  - 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前
- 但是**不能解决指令交错问题**
  - 写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证读跑到它前面去
  - 而有序性的保证也只是保证了本线程内相关代码不被重排序 

> **进一步说明**：
>
> 由于编译器和处理器都能执行指令重排的优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和CPU，不管什么指令都不能和这条 Memory Barrier 指令重排序，也就是说**通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化**。 内存屏障**另外一个作用是刷新出各种 CPU 的缓存数**，因此任何 CPU 上的线程都能读取到这些数据的最新版本。
>
> ![内存屏障](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809735.png)

### synchronized 和 volatile 的区别 :exclamation::exclamation:

synchronized关键字和volatile关键字比较

* **性能方面**：**volatile关键字是线程同步的轻量级实现**，所以volatile性能肯定比synchronized关键字要好；因为：多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞
* **作用范围**：volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块。
* synchronized 关键字在 Java 1.6 之后进行了一些优化，如：引入的偏向锁和轻量级锁等，从而减少获得锁和释放锁带来的性能消耗，实际开发中使用 synchronized 关键字的场景还是更多⼀些。
* volatile关键字能保证数据的可见性，但**不能保证数据的原子性**。 synchronized关键字两者都能保证。
* **作用方面**：volatile关键字主要用于解决变量在多个线程之间的**可见性**，而 synchronized 关键字解决的是多个线程之间访问资源的**同步性**

### 单例模式：双重检查锁DCL :exclamation:

DCL：Double Check Lock

```java
/**
 * SingletonDemo（单例模式）
 */
public class Singleton {

    // 这里必须加上volatile关键字
    private static volatile Singleton INSTANCE = null;

    private Singleton () {}

    // 单例模式获取对象信息
    public static Singleton getInstance() {

        if (INSTANCE != null) {
            return INSTANCE;
        }
        
        // 双重检查加锁多线程情况下会出现：线程A已经执行到☆处，没有完成初始化；则线程B还是能到这里
        // 然后在线程A完成初始化后，B还是能拿到这把锁，因此后续要在进行一次null的判断
        synchronized (Singleton.class){ 	
            if (INSTANCE != null) { // t2
                return INSTANCE;
            }
            // ☆此时才开始初始化
            INSTANCE = new Singleton();
            return INSTANCE;
        }
    }
}
```

需要注意的是：**instance 必须使用 volatile 关键词进行修饰**，理由如下：因为**指令重排**的存在，而加入 volatile 可以禁止指令重排

原因是在某一个线程执行到第一次检测的时候，读取到 instance 不为 null，而由于指令重排操作，此时 instance 的引用对象可能**没有完成实例化**。

> 进一步说明：
>
> 因为 `instance = new Singleton()`；可以分为以下三步进行完成：
>
> ```java
> memory = allocate(); 	// 1、分配对象内存空间
> instance(memory); 		// 2、初始化对象
> instance = memory; 		// 3、设置instance指向刚刚分配的内存地址，此时instance != null
> ```
>
> 但是我们通过上面的三个步骤，能够发现，步骤2 和 步骤3之间**不存在数据依赖关系**，而且无论重排前还是重排后，程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。
>
> ```java
> memory = allocate(); 	// 1、分配对象内存空间
> instance = memory; 		// 3、设置instance指向刚刚分配的内存地址，此时instance != null，但是对象还没有初始化完成
> instance(memory); 		// 2、初始化对象
> ```
>
> 这样就会造成什么问题呢？**出现了先赋值再进行构造的情况**
>
> **所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，这就造成了线程安全的问题**
>
> 所以需要引入 volatile，来保证出现指令重排的问题，从而保证单例模式的线程安全性：
>
> ```java
> private static volatile Singleton INSTANCE = null;
> ```

### ThreadLocal 简介 :exclamation::exclamation::exclamation:

通常情况下，我们创建的变量是可以被任何⼀个线程访问并修改的。 如果想**实现每⼀个线程都有自己的专属本地变量**该如何解决呢？

JDK 中提供的 ThreadLocal 类正是为了解决这样的问题。

**ThreadLocal 类主要解决的就是让每个线程绑定自己的值**。

如果你创建了⼀个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是 ThreadLocal 变量名的由来。他们可以使用 `get()` 和 `set()` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 

> 再举个简单的例子：比如有两个人去宝屋收集宝物，这两个共用⼀个袋子的话肯定会产生争执，但是给他们两个人每个人分配⼀个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么 ThreadLocal 就是用来避免这两个线程竞争的。 
>

### ThreadLocal 使用

> 传送门：[Java：ThreadLocal小记：4. ThreadLocal的核心方法源码](https://www.cnblogs.com/zhuchengchao/p/14437915.html)

在使用之前,我们先来认识几个ThreadLocal的常用方法

| 方法声明                    | 描述                       |
| --------------------------- | -------------------------- |
| `ThreadLocal()`             | 创建ThreadLocal对象        |
| `public void set( T value)` | 设置当前线程绑定的局部变量 |
| `public T get()`            | 获取当前线程绑定的局部变量 |
| `public void remove()`      | 移除当前线程绑定的局部变量 |

> 后续的方法这里都不上源码，详见专门的笔记

**set方法**

代码执行流程：

1. 首先获取当前线程，并根据当前线程获取一个 ThreadLocalMap
2. 如果获取的 ThreadLocalMap 不为空，则将参数设置到 ThreadLocalMap 中（当前 ThreadLocal 的引用作为key）
3. 如果 ThreadLocalMap 为空，则给该线程创建 ThreadLocalMap，并设置初始值

**get方法**

1. 首先获取当前线程
2. 根据当前线程获取一个Map
3. 如果获取的Map不为空，则在Map中以ThreadLocal的引用作为key来在Map中获取对应的value e，否则转到5
4. 如果e不为null，则返回 e.value，否则转到 5
5. Map为空或者e为空，则通过 initialValue 函数获取初始值 value，然后用 ThreadLocal 的引用和 value 作为firstKey 和 firstValue 创建一个新的Map

总结: **先获取当前线程的 ThreadLocalMap 变量，如果存在则返回值，不存在则创建并返回初始值。**

**remove方法**

1. 首先获取当前线程，并根据当前线程获取一个Map
2. 如果获取的Map不为空，则移除当前ThreadLocal对象对应的entry

**initialValue方法**

> 这里就不上源码，详见专门的笔记

 此方法的作用是 返回该线程局部变量的初始值。

1. 这个方法是一个延迟调用方法，从上面的代码我们得知，在set方法还未调用而先调用了get方法时才执行，并且仅执行1次。
2. 这个方法缺实现直接返回一个`null`。
3. 如果想要一个除null之外的初始值，可以重写此方法。（备注： 该方法是一个`protected`的方法，显然是为了让子类覆盖而设计的）

**实例代码**：

```java
public class Demo01 {

    // 创建一个 ThreadLocal 对象
    ThreadLocal<String> tl = new ThreadLocal<>();

    private String getContent() {
        return tl.get();
    }

    private void setContent(String content) {
        // 将变量绑定到ThreadLocal中
        tl.set(content);
    }

    public static void main(String[] args) {
        Demo01 demo = new Demo01();
        for (int i = 0; i < 5; i++) {
            Thread thread = new Thread(() -> {
                // 每个线程：存一个变量，过一会儿取出这个变量
                String name = Thread.currentThread().getName();
                demo.setContent(name + "的数据");
                System.out.println("------");
                System.out.println(name + "--->" + demo.getContent());
            });
            thread.setName("线程" + i);
            thread.start();
        }
    }
}
```

### ThreadLocal 结构 :exclamation:

```java
public class Thread implements Runnable {
    // 与此线程有关的ThreadLocal值，由ThreadLocal类维护
    ThreadLocal.ThreadLocalMap threadLocals = null;
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
}
```

JDK8  ThreadLocal 的设计是：**每个 Thread 维护一个 ThreadLocalMap 哈希表，这个哈希表的 key 是 ThreadLocal 实例本身， value 才是真正要存储的值 Object**。

1. 每个 Thread 线程内部都有一个 ThreadLocalMap
2. Map 里面存储 ThreadLocal 对象（key）和线程的变量副本（value）
3. Thread 内部的 Map 是由 ThreadLocal 维护的，由 ThreadLocal 负责向 map 获取和设置线程的变量值。
4. 对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成了副本的隔离，互不干扰。

![现在ThreadLocal设计](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809260.PNG)

**这样设计的好处**：这个设计与我们一开始说的设计（对每个 ThreadLocal 类创建一个 Map，Thread作为Key，存储的变量作为value）刚好相反，这样设计有如下两个优势：

1. 这样设计之后每个`Map`存储的`Entry`数量就会变少，因为之前的存储数量由`Thread`的数量决定，现在是由`ThreadLocal`的数量决定，实际开发中，`ThreadLocal`的数量往往少于`Thread`的数量；
2. 当`Thread`销毁之后，对应的`ThreadLocalMap`也会随之销毁，能减少内存的使用。

> 进一步对 ThreadLocal 的结构进行分析：
>
> ThreadLocalMap 是 ThreadLocal 的静态内部类，没有实现 Map 接口，用独立的方式实现了 Map 的功能，其内部的 Entry 也是独立实现。
>
> ![ThreadLocalMap基本结构](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809731.PNG)
>
> ```java
> static class ThreadLocalMap {
>    
>        // 初始容量:必须是2的整次幂
>     	private static final int INITIAL_CAPACITY = 16;
>        // 存放数据的table，Entry类的定义在下面分析,同样，数组长度必须是2的冥。
>        private Entry[] table;
>        // 数组里面entrys的个数，可以用于判断table当前使用量是否超过负载因子。
>        private int size = 0;
>        // 进行扩容的阈值，表使用量大于它的时候进行扩容。
>        private int threshold; // Default to 0
>        // 阈值设置为长度的2/3
>        private void setThreshold(int len) {
>            threshold = len * 2 / 3;
>        }
>    
>        /**
>       * Entry继承 WeakReference，并且用ThreadLocal作为key，
>       * 如果key为null(entry.get()==null)，意味着key不再被引用，
>       * 因此这时候entry也可以从table中删除
>          */
>        static class Entry extends WeakReference<ThreadLocal> {
>            /** The value associated with this ThreadLocal. */
>            Object value;
> 
>            Entry(ThreadLocal k, Object v) {
>                super(k);
>                value = v;
>            }
>        }
> }
> ```
>
> 在 ThreadLocalMap 中，也是用 Entry 来保存 K-V 结构数据的。**但是Entry中key只能是ThreadLocal对象**，这点被Entry的构造方法已经限定死了；
>
> 另外，Entry继承WeakReference，**也就是key（ThreadLocal）是弱引用，其目的是将ThreadLocal对象的生命周期和线程的生命周期解绑**，可以使得 ThreadLocal 在没有其他强引用的时候被回收掉，这样可以避免因为线程得不到销毁导致ThreadLocal对象无法被回收的情况。
> 

### ThreadLocal 内存泄露问题 :exclamation::exclamation::exclamation:

有些程序员在使用 ThreadLocal 的过程中会发现有内存泄漏的情况发生，就猜测这个内存泄漏跟 Entry 中使用了弱引用的 key 有关系。这个理解其实是不对的。

> 我们先来回顾这个问题中涉及的几个名词概念,再来分析问题。
>
> 1. **内存泄漏相关概念**
>
>    **Memory overflow**：内存溢出，没有足够的内存提供申请者使用。
>
>    **Memory leak**：内存泄漏是指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果，内存泄漏的堆积终将导致内存溢出。
>
> 2. **弱引用相关概念**
>
>    Java中的引用有4种类型: 强、软、弱、虚。当前这个问题主要涉及到强引用和弱引用:
>
>    **强引用( “Strong” Reference)** ，就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾回收器就不会回收这种对象。
>
>    **弱引用( WeakReference)**，垃圾回收器一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。
>
> 3. **如果key使用强引用**
>
>    假设 ThreadLocalMap 中的 key 使用了强引用，那么会出现内存泄漏吗？
>
>    此时 ThreadLocal 的内存图(实线表示强引用)如下:
>
>    ![若key使用强引用](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809763.PNG)
>
>    1. 假设在业务代码中使用完 ThreadLocal，ThreadLocal Ref 被回收了；
>    2. 但是因为 ThreadLocalMap 的 Entry 强引用 ThreadLocal，**造成 ThreadLocal 无法被回收**；
>    3. 在没有手动删除这个 Entry 以及 CurrentThread 依然运行的前提下，始终有强引用链`Current threadRef->currentThread->threadLocalMap->entry`，Entry 就不会被回收（Entry 中包括了 ThreadLocal 实例和 value），**导致 Entry 内存泄露**。
>
>    也就是说，ThreadLocalMap 中的 key 使用了强引用，是无法完全避免内存泄露的。
>
> 4. **如果key使用弱引用**
>
>    那么 ThreadLocalMap 中的 key 使用了弱引用，那么会出现内存泄漏吗?
>
>    ![若key使用弱引用](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809907.PNG)
>
>    1. 同样假设在业务代码中使用完 ThreadLocal，ThreadLocal Ref 被回收了；
>    2. 由于 ThreadLocalMap 只持有 ThreadLocal 的弱引用，没有任何强引用指向 ThreadLocal 实例，**所以 ThreadLocal 就可以顺利被GC回收了**，此时 Entry 中的key=null；
>    3. 但是在没有手动删除这个 Entry 以及 CurrentThread 依然运行的前提下，也存在有强引用链`Current threadRef->currentThread->threadLocalMap->entry->value`，value 不会被回收，而这块value永远不会被访问到了，**导致value内存泄露**。
>
>    也就是说，ThreadLocalMap 中的 key 使用了弱引用，也可能内存泄露。

**出现内存泄露的原因**

比较以上两种情况，我们发现，内存泄露的发生跟 ThreadLocalMap 中的 key 是否使用弱引用是没有关系的，那么内存泄露真正的原因是什么呢？

又可以发现，以上两种内存泄露的情况中，都有两个前提：

1. **没有手动删除这个Entry；**
2. **CurrentThread 依然在运行。**

第1点很好理解，只要在使用完 ThreadLocal，调用其 remove 方法删除对应的 Entry，就能避免内存泄露；

第2点稍微复杂一点，由于 ThreadLocalMap 是 Thread 的一个属性，被当前线程所引用，所以它的生命周期跟 Thread 一样长。那么在使用完 ThreadLocal 后，如果当前 Thread 也随之结束，ThreadLocalMap自然也会被 GC 回收，从根源上避免了内存泄露。

对于第2点，实现使用完 ThreadLocal，将当前的 Thread 结束不好控制，特别是使用线程池的时候，线程结束是不会被销毁的。

综上，ThreadLocal 内存泄露的根源是：**由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应Entry就会导致内存泄露。**

也就是说，只要记得在使用完 ThreadLocal 及时的调用 remove，无论 key 是强引用还是弱引用都不会有内存泄露问题。

**那么为什么key要用弱引用呢?**

事实上，在 ThreadLocalMap 中的 set/getEntry 方法中，会对 key 为 null (也即是 ThreadLocal 为 null )进行判断，如果为 null 的话，那么是会对 value 置为 null 的。

这就意味着使用完 ThreadLocal，CurrentThread 依然运行的前提下，**就算忘记调用 remove 方法，弱引用比强引用可以多一层保障**：弱引用的 ThreadLocal 会被回收，对应的 value 在下一次 ThreadLocalMap 调用 set，get，remove 中的任一方法的时候会被清除，从而避免内存泄漏。

### ThreadLocal 与 synchronized 的区别 :exclamation:

虽然 ThreadLocal 模式与 synchronized 关键字都用于处理**多线程并发访问变量**的问题，不过两者处理问题的角度和思路不同。

|        | synchronized                                                 | ThreadLocal                                                  |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 原理   | 同步机制采用**以时间换空间**的方式, **只提供了一份变量,让不同的线程排队访问** | ThreadLocal采用**以空间换时间**的方式, **为每一个线程都提供了一份变量的副本**,从而实现同时访问而相不干扰 |
| 侧重点 | 多个线程之间访问资源的**同步性**                             | 多线程中让每个线程之间的数据**相互隔离**                     |

总结： 虽然使用 ThreadLocal 和 synchronized 都能解决问题,但是**使用 ThreadLocal 可以使程序拥有更高的并发性。**

### 使用线程池的原因 & 线程组 :exclamation:

> **什么是线程组？**
>
> * ThreadGroup 类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。
>
> **为什么不推荐使用线程组？**
>
> * 因为使用有很多的安全隐患吧，没有具体追究，**如果需要使用，推荐使用线程池**。
>
> **线程池和线程组**
>
> * 线程组和线程池是两个不同的概念，他们的作用完全不同：
>* **线程组：为了方便线程的管理**；
> * **线程池：为了管理线程的生命周期，复用线程，减少创建销毁线程的开销**。

**使用线程池的好处：**

* **降低资源消耗**：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
* **提高响应速度**：当任务到达时，任务可以不需要再等到线程创建就能立即执行。
* **提高线程的可管理性**：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统⼀的分配，调优和监控。 

### Runnable & Callable & Future & FutureTask

**Runnable 接口**

实现 Runnable 接口的时候，需要重写 run 方法，也就是线程在启动的时候，会自动调用的方法

```java
public interface Runnable {
    public abstract void run();
}
```

没有返回值，且不能抛出异常信息

**Callable 接口**

Callable 接口，是一种让线程执行完成后，**能够返回结果的**，在实现 Callable 接口，需要**实现 call 方法**，但是这个时候我们还需要有返回值，

```java
@FunctionalInterface
public interface Callable<V> {
    V call() throws Exception;
}
```

**Runnable 与 Callable 的区别：**

1. `Runnable(java.lang.Runnable)`是自从 java1.1 就有了，而`Callable(java.util.concurrent...)`是1.5之后才加上去的。

2. Callable规定的方法是`call()`，Runnable规定的方法是`run()`

3. **Callable的任务执行后可返回值，而Runnable的任务是不能返回值(是void)**

4. **call方法可以抛出异常，run方法不可以**

5. 运行Callable任务可以拿到一个 Future 对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果

6. 加入线程池运行，Runnable 使用 ExecutorService 的`execute()`方法，Callable 使用`submit()`方法

   > 需要注意的是：ExecutorService 中的`execute()`方法是继承自Executor类的，而`submit()`其本身就有的

**Future 接口**

```java
public interface Future<V> {

    boolean isCancelled();

    boolean isDone();

    V get() throws InterruptedException, ExecutionException;
    
    // 有时间的等待
    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
}
```

Future 是一个接口。相当于存储器，通过将 Future 对象传递给 Thread，让其获取线程执行的返回值结果并进行处理。

Future 可以通过 `get()` 方法来获取 Callable 的 call 方法的任务结果。还可以通过`isDone()` 来判断任务是否已经执行完毕，还可以通过`cancel()`来取消这个任务，或者限时获取任务的执行结果

**FutureTask 类**

FutureTask 是 Future 的唯一的一种具体的实现，同样实现了`get()`、`cancel()`、`isCancel()`、`isDone()`方法。

```java
public class FutureTask<V> implements RunnableFuture<V> {}
public interface RunnableFuture<V> extends Runnable, Future<V> {}
```

他实现了 Runnable 接口，并且还需要传递一个实现 Callable 接口的类作为构造函数

1. Thread 实现了 Runable 接口，因此 Thread 中可以传入 Runable 接口，及其子接口；
2. FutureTask 实现了 RunnableFuture 接口，而 RunnableFuture 接口继承了 Runable 接口；
3. 在 FutureTask 的构造函数中，可以传入 Callable 接口：`public FutureTask(Callable<V> callable)`

```java
class MyThread2 implements Callable<Integer> {
    @Override
    public Integer call() throws Exception {
        System.out.println("come in Callable");
        return 1024;
    }
}

// 这里通过了 FutureTask 接触了 Callable 接口
FutureTask<Integer> futureTask = new FutureTask<>(new MyThread2());

// 然后在用 Thread 进行实例化，传入实现 Runnabnle 接口的 FutureTask 的类
Thread t1 = new Thread(futureTask, "aaa");
t1.start();

// 最后通过 `FutureTask.get()` 获取到返回值
// 输出 FutureTask 的返回值
System.out.println("result FutureTask " + futureTask.get());
```

这就相当于原来我们的方式是 main 方法一条龙执行，后面在引入 Callable 后，对于执行比较久的线程，可以单独新开一个线程进行执行，最后再进行汇总输出；

最后需要注意的是要求获得 Callable 线程的计算结果，如果没有计算完成就要去强求，会导致阻塞，直到计算完成

也就是说 `futureTask.get()` 需要放在最后执行，这样不会导致主线程阻塞

也可以使用下面算法，使用类似于自旋锁的方式来进行判断是否运行完毕

```java
// 判断 futureTask 是否计算完成
while(!futureTask.isDone()) { }
```

### `execute()` 和 `submit()` 的区别

`execute()` 用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； 

```java
// 传入的是Runnable接口
public void execute(Runnable command) {}
```

`submit()` 用于提交需要返回值的任务。线程池会返回⼀个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 `get()` 方法来获取返回值， `get()` 方法会阻塞当前线程直到任务完成，而使用 `get(long timeout，TimeUnit unit)` 方法则会阻塞当前线程⼀段时间后立即返回，这时候有可能任务没有执行完。

```java
<T> Future<T> submit(Callable<T> task);
V get() throws InterruptedException, ExecutionException;
V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
```

### Executors & Executor & Executor框架 :exclamation:

**Executors**：

* Executors 为工具类，其提供了不同方法按照我们的需求来创建不同的线程池，来满足业务的需求

**Executor：**

* Executor 接口对象能执行我们的线程任务。

  ```java
  public interface Executor {
  	void execute(Runnable command);
  }
  ```

  ExecutorService 接口继承了 Executor 接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。

  ```java
  public interface ExecutorService extends Executor {
      // 执行任务
  	void execute(Runnable command);
      // 提交任务 task，用返回值 Future 获得任务执行结果
      <T> Future<T> submit(Callable<T> task);
      // 提交 tasks 中所有任务
  	public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks) throws InterruptedException;
      // 关闭线程池
      void shutdown();
  }
  ```

**Executor 框架**：

* Executor 框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。

* **不使用 Executor 框架存在的问题：**
  1. 首先若不使用该框架，而是每次执行任务创建线程 `new Thread()` 比较消耗性能，创建一个线程是比较耗时、耗资源的。
  2. 调用 `new Thread()` 创建的线程缺乏管理，被称为**野线程**，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。
  3. 且使用 `new Thread()` 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。
* 所以**创建一个线程池**是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程，**而利用 Executor 框架可以非常方便的创建一个线程池**。
* **使用 Executors 线程池框架的优点**：
  1. 能**复用**已存在并空闲的线程从而降低线程创建和销毁造成的消耗。
  2. 可有效控制最大并发线程数，提高系统资源使用率，同时避免过多资源竞争。
  3. 框架中已经有定时、定期、单线程、并发数控制等功能。
* **综上所述**：使用线程池框架 Executor 能更好的管理线程、提高系统资源使用率。

> 但是还是不推荐通过 Executors 直接创建线程池，而是**更推荐通过 ThreadPoolExecutor 来创建线程池**，后续会分析

### 线程池的创建方式 :exclamation::exclamation:

**通过 Executors 去创建**

**Executors 为工具类**，其提供了不同方法按照我们的需求来创建不同的线程池，来满足业务的需求。

- **Executors.newFixedThreadPool(int i)** ：创建一个拥有 i 个线程的线程池
  - 执行长期的任务，性能好很多
  - 创建一个定长线程池，可控制线程数最大并发数，超出的线程会在队列中等待
- **Executors.newSingleThreadExecutor()**：创建一个只有1个线程的单线程池
  - 一个任务一个任务执行的场景
  - 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行
- **Executors.newCacheThreadPool()**：创建一个可扩容的线程池
  - 执行很多短期异步的小程序或者负载较轻的服务器
  - 创建一个可缓存线程池，如果线程长度超过处理需要，可灵活回收空闲线程，如无可用线程，则新建新线程
- **Executors.newScheduledThreadPool(int corePoolSize)**：
  - 线程池支持定时以及周期性执行任务
  - corePoolSize 为传入参数，最大线程数为整形的最大数的线程池

**方法的底层都是通过 ThreadPoolExecutor 去创建线程池**

我们通过查看源码，点击了 `Executors.newFixedThreadPool` 、 `Executors.newSingleThreadExecutor` 、 `Executors.newCachedThreadPool` 能够发现底层都是使用了 **ThreadPoolExecutor**

```java
// 创建固定线程数的线程池
public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue<Runnable>());
}

// 创建仅有一个线程的线程池
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}

// 创建可扩容的线程池
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```

我们可以看到线程池的内部，还使用到了 `LinkedBlockingQueue` 链表阻塞队列

而 `Executors.newCacheThreadPool` 底层用的是 `SynchronousBlockingQueue` 同步阻塞队列

> **Executors.newScheduledThreadPool(int corePoolSize)**：
>
> ```java
> // 创建支持定时及周期性执行任务的线程池，可以见到最终还是使用了ThreadPoolExecutor来创建线程池
> // 1.Executors类中
> public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
>        return new ScheduledThreadPoolExecutor(corePoolSize);
> }
> // 2.ScheduledThreadPoolExecutor类中
> public ScheduledThreadPoolExecutor(int corePoolSize) {
>        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
>              new DelayedWorkQueue());  // DelayedWorkQueue 延迟阻塞队列
> }
> // 3.ThreadPoolExecutor类中
> public ThreadPoolExecutor(int corePoolSize,
>                              int maximumPoolSize,
>                              long keepAliveTime,
>                              TimeUnit unit,
>                              BlockingQueue<Runnable> workQueue) {
>        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
>             Executors.defaultThreadFactory(), defaultHandler);
> }
> ```

### ThreadPoolExecutor 类分析:exclamation::exclamation:

```java
public ThreadPoolExecutor(int corePoolSize,     // 核心线程数
                          int maximumPoolSize,  // 最大线程数
                          long keepAliveTime,   // 多余线程存活时间
                          TimeUnit unit,        // 多余线程存活时间单位
                          BlockingQueue<Runnable> workQueue,  // 任务队列
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
	// ...
}
```

线程池在创建的时候，一共有7大参数：

- **corePoolSize**：核心线程数，线程池中的常驻核心线程数
  - 在创建线程池后，当有请求任务来之后，就会安排池中的线程去执行请求任务，近似理解为今日当值线程
  - 当线程池中的线程数目达到 corePoolSize 后，就会把之后的任务放到缓存队列workQueue中
- **maximumPoolSize**：线程池能够容纳同时执行的最大线程数，此值必须大于等于1
  - 相当于扩容后的线程数，这个线程池能容纳的最多线程数
- **keepAliveTime**：多余的空闲线程存活时间
  - 当线程池数量超过 corePoolSize 时，又当空闲时间达到 keepAliveTime 值时，多余的空闲线程会被销毁，直到只剩下 corePoolSize 个线程
  - 默认情况下，只有当线程池中的线程数大于 corePoolSize 时，keepAliveTime 才会起作用
- **unit**：keepAliveTime 的单位
- **workQueue**：任务队列，被提交的但未被执行的任务（类似于银行里面的候客区）
  - LinkedBlockingQueue：链表阻塞队列
  - SynchronousBlockingQueue：同步阻塞队列
- **threadFactory**：表示生成线程池中工作线程的线程工厂，用于创建线程池一般用默认即可
- **handler**：拒绝策略，表示当队列满了并且工作线程大于线程池的最大线程数（maximumPoolSize）时，如何来拒绝请求执行的 Runnable 的策略

**拒绝策略**

以下所有拒绝策略都实现了 RejectedExecutionHandler 接口

- **AbortPolicy**：默认，直接抛出 RejectedExcutionException 异常，阻止系统正常运行
- **DiscardPolicy**：直接丢弃任务，不予任何处理也不抛出异常，如果允许运行任务丢失，这是一种好方案
- **CallerRunsPolicy**：该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者
- **DiscardOldestPolicy**：抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务

### 线程池底层工作原理:exclamation::exclamation:

**线程池运行架构图**

![线程池运行架构图](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809750.png)

**文字说明**

1. 在创建了线程池后，等待提交过来的任务请求
2. 当调用 `execute()` 方法添加一个请求任务时，线程池会做出如下判断
   1. 如果正在运行的线程池数量小于 corePoolSize，那么马上创建线程运行这个任务
   2. 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列
   3. 如果这时候队列满了，并且正在运行的线程数量还小于 maximumPoolSize，那么还是创建非核心线程运行这个任务；
   4. 如果队列满了并且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会启动饱和拒绝策略来执行
3. 当一个线程完成任务时，它会从队列中取下一个任务来执行
4. 当一个线程无事可做，当超过一定的时间(keepAliveTime)时，线程池会判断：
   1. 如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉
   2. 所以线程池的所有任务完成后，它会最终收缩到 corePoolSize 的大小

> 以顾客去银行办理业务为例，谈谈线程池的底层工作原理
>
> ![线程池](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809663.png)
>
> 1. 最开始假设来了两个顾客，因为 corePoolSize 为2，因此这两个顾客直接能够去窗口办理
> 2. 后面又来了三个顾客，因为 corePool 已经被顾客占用了，因此只有去候客区，也就是阻塞队列中等待
> 3. 后面的人又陆陆续续来了，候客区可能不够用了，因此需要申请增加处理请求的窗口，这里的窗口指的是线程池中的线程数，以此来解决线程不够用的问题
> 4. 假设受理窗口已经达到最大数，并且请求数还是不断递增，此时候客区和线程池都已经满了，为了防止大量请求冲垮线程池，已经需要开启拒绝策略
> 5. 临时增加的线程会因为超过了最大存活时间，就会销毁，最后从最大数削减到核心数

### 为什么不用 Executors 创建线程池 :exclamation:

使用 Executors 线程池创建的方法有：

- 固定数的：newFixedThreadPool
- 单一的：newSingleThreadExecutor
- 可变的：newCachedThreadPool

那么在实际开发中，应该使用哪个？

**我们一个都不用，在生产环境中是使用自己自定义的**

为什么不用 JDK 提供的 Executors 来创建线程池？

根据阿里巴巴手册：并发控制这章，有如下：

- **线程资源必须通过线程池提供，不允许在应用中自行显式创建线程**
  - 使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题
  - 如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题
- **线程池不允许使用 Executors 去创建，而是通过 ThreadToolExecutors 的方式**，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。
  - Executors 返回的线程池对象**弊端如下**：
    - FixedThreadPool 和 SingleThreadPool：运行的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM
    - CacheThreadPool 和 ScheduledThreadPool：运行的请求队列长度为：Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM

### 原子类 & 原子操作 & CAS :exclamation:

原子操作（atomic operation）意为"**不可被中断的一个或一系列操作**” 

在 Java 中可以通过**锁**和**循环 CAS** 的方式来实现原子操作。

* CAS 操作：`Compare & Set` 或是 `Compare & Swap`，现在几乎所有的 CPU 指令都支持 CAS 的原子操作，它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，**这个过程是原子的**
* **也就是说 CAS 是一条 CPU 的原子指令，不会造成所谓的数据不一致的问题，也就是说 CAS 是线程安全的**

**原子操作是指一个不受其他操作影响的操作任务单元**。原子操作是在多线程环境下避免数据不一致必须的手段。

例如：`int++` 并不是一个原子操作，所以当一个线程读取它的值并加 1 时，另外一个线程有可能会读到之前的值，这就会引发错误。

为了解决这个问题，必须保证增加操作是原子的，在 JDK1.5 之前我们可以使用同步技术来做到这一点。到 JDK1.5，`java.util.concurrent.atomic` 包提供了 int 和 long 类型的**原子包装类**，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步，而是通过 CAS 进行保证：

* CAS 是 `compareAndSwap`，**比较当前工作内存中的值和主物理内存中的值**，如果相同则执行规定操作，否者继续比较直到主内存和工作内存的值一致为止

* CAS 有3个操作数，内存值V，旧的预期值A，要修改的更新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否者什么都不做。

> `java.util.concurrent` 这个包里面提供了一组原子类。
>
> - 原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference
> - 原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray
> - 原子属性更新器：AtomicIntegerFieldUpdater，AtomicLongFieldUpdater，AtomicReferenceFieldUpdater
> - 解决 ABA 问题的原子类：
>   - AtomicMarkableReference（通过引入一个 boolean 来反映中间有没有变过）
>   - AtomicStampedReference（通过引入一个 int 来累加来反映中间有没有变过）

### CAS 与 synchronized :exclamation::exclamation:

**结合 CAS 和 volatile 可以实现无锁并发，适用于线程数少、多核 CPU 的场景下。** 

- CAS 是基于**乐观锁**的思想：最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，我吃亏点再重试呗。
- synchronized 是基于**悲观锁**的思想：最悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。
- CAS 体现的是无锁并发、无阻塞并发，请仔细体会这两句话的意思
  - 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一
  - 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 

### LockSupport 之 park & unpark

LockSupport 为 `java.util.concurrent.locks` 包下的工具，其主要提供了 `park` 和 `unpark` 方法，这两个方法主要用于阻塞线程和解锁阻塞线程，其可以让线程在任意位置阻塞，在阻塞之后也有对应的唤醒方法。

> 3种让线程等待和唤醒的方法
>
> 1. synchronize：使用 Object 中的 `wait()` 方法让线程等待，使用 Object 中的 `notify()` 方法唤醒线程；
> 2. ReentrantLock：使用 Condition 的 `await()` 方法让线程等待，使用 `signal()` 方法唤醒线程；
> 3. LockSupport：阻塞当前线程以及唤醒指定被阻塞的线程

**特点**：与 Object 的 wait & notify 相比

- wait，notify 和 notifyAll 必须配合 Object Monitor 一起使用，而 park，unpark 不必
- park & unpark 是**以线程为单位**来『阻塞』和『唤醒』线程，而 notify 只能随机唤醒一个等待线程，notifyAll 是唤醒所有等待线程，就不那么精确
- park & unpark 可以**先 unpark**，而 wait & notify 不能先 notify

**原理**：

- 每个线程都有自己的一个 Parker 对象，由三部分组成 `_counter` ， `_cond` 和 `_mutex` 
- 当在线程中调用 `LockSupport.park()` 方法时，若该线程的 Parker 对象 `_counter` 值为0，则线程进入阻塞状态；
- 当调用 `LockSupport.unpark(线程对象)`时，会令刚刚因  `unpark()` 而阻塞的线程恢复运行；
- 特别注意：当线程未阻塞时，也可以多次调用 `LockSupport.unpark(线程对象)` 方法，这会令此时线程的 Parker 对象 `_counter` 值为 1，而当在该线程中调用 `park()` 方法时，会消耗这个 `_counter` 值，由于消耗完之后为 0，因此线程不会阻塞，而是继续运行；
- 但是考虑到 `_counter` 值最大为1，当调用一次 `park()` 方法消耗完之后，再次调用 `park()` 线程还是会进入阻塞状态。

**注意点**

- 当 park 住的线程被打断后，打断标志位会被置为 true；
- 此时再次 park 线程时，park无效，即：**当线程的打断标志位为 true 时，再次 park 无效**
- 可以通过 `Thread.interrupted()` 清除打断标志位；而方法 `isInterrupted` 是不会清除打断标志位的

> 进一步理解见：[Java：并发笔记-03：3.9 Park & Unpark](https://www.cnblogs.com/zhuchengchao/p/14491216.html)

### AQS：谈谈对AQS的理解 :exclamation::exclamation::exclamation:

> 传送门：[Java：AQS 小记-1(概述)](https://www.cnblogs.com/zhuchengchao/p/14799761.html)

全称是 Abstract Queued Synchronizer（抽象队列同步器），是**阻塞式锁和相关的同步器工具的框架**，这个类在 `java.util.concurrent.locks` 包下面。

 **AQS 的核心思想**：

- 如果被请求的共享资源**空闲**，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。
- 如果被请求的共享资源**被占用**，那么就需要⼀套**线程阻塞等待**以及**被唤醒时锁分配**的机制，这个机制 AQS 是用 **CLH 队列**实现的，即将暂时获取不到锁的线程加入到队列中。

**state 变量**：

* **AQS 使用⼀个 int 类型的成员变量 state 来表示资源（独占/共享）的状态**

  ```java
  // 共享变量，使用volatile修饰保证线程可见性
  private volatile int state;
  
  // state 状态信息通过方法getState/setState/compareAndSetState进行获取与修改
  // 获取 state 状态
  protected final int getState() {
      return state;
  }
  
  // 设置 state 状态
  protected final void setState(int newState) {
      state = newState;
  }
  
  // cas 机制设置state状态
  protected final boolean compareAndSetState(int expect, int update) {
      return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
  }
  ```

**AQS 对资源的占用分为两种方式：Exclusive（独占）与 Share（共享）**

  * **Exclusive（独占）**：只有⼀个线程能执行，如 ReentrantLock，又可分为公平锁和非公平锁：
    - **公平锁**：多个线程按照申请锁的顺序去获取锁，线程会先进入队列中进行排队，因此队列中第一个线程会先获得锁资源；
    - **非公平锁**：当线程要获取锁时，**会先尝试获得锁**，获取不到再进入队列等待（**队列中等待的线程还是遵循FIFO的**）。因此当有新来的线程获取锁时，存在和队列中等待的线程互相竞争的情况，因此是非公平的。
  * **Share（共享）**：多个线程可同时执行，如 Semaphore / CountDownLatch。 

  > ReentrantReadWriteLock 可以看成是**组合式**，因为 ReentrantReadWriteLock 也就是读写锁，允许多个线程同时对某⼀资源进行读。

**CLH 队列**

* CLH（Craig + Landin + Hagersten）队列是⼀个虚拟的双向队列（虚拟的双向队列即不存在队列实例，**仅存在结点之间的关联关系**）

* AQS 是将每条请求共享资源的线程封装成⼀个 CLH 锁队列的⼀个结点（Node），来完成获取资源线程的排队工作。

  ![AQS原理图](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809856.PNG)

**如何自定义同步器**

* 不同的自定义同步器争用共享资源的方式不同。**自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可**，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。 

* **AQS 底层使用了模板方法模式**

  同步器的设计是基于模板方法模式的，如果需要自定义同步器⼀般的方式是这样（模板方法模式很经典的⼀个应用）：

  1. 使用者继承 AbstractQueuedSynchronizer 并重写指定的方法。（这些重写方法很简单，无非是对于共享资源 state 的获取和释放）
  2. 将 AQS 组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。

* 主要就是子类实现**以下几个模版方法**：

  ```java
  // 该线程是否正在独占资源。
  protected boolean isHeldExclusively() {
      throw new UnsupportedOperationException();
  } 
  
  // 独占方式:尝试获取资源，成功则返回true，失败则返回false。
  protected boolean tryAcquire(int arg) {
      throw new UnsupportedOperationException();
  }      
  // 独占方式:尝试释放资源，成功则返回true，失败则返回false。
  protected boolean tryRelease(int arg) {
      throw new UnsupportedOperationException();
  }    
  
  // 共享方式：尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
  protected int tryAcquireShared(int arg) {
      throw new UnsupportedOperationException();
  }
  // 共享方式：尝试释放资源，成功则返回true，失败则返回false。
  protected boolean tryReleaseShared(int arg) {
      throw new UnsupportedOperationException();
  }
  ```

  默认情况下，**每个方法都抛出 UnsupportedOperationException，因此自定义同步器时必须重写要用到的方法。 **AQS 类中的其他方法都是 final ，所以无法被其他类重写，只有这几个方法可以被其他类重写。

  ⼀般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现 `tryAcquire-tryRelease`、`tryAcquireShared-tryReleaseShared` 中的⼀种即可。但 AQS 也⽀持自定义同步器同时实现独占和共享两种方式，如 ReentrantReadWriteLock。

**AQS 已有实现**

* **以 ReentrantLock 为例**：
  * state初始化为0，表示未锁定状态。
  * A线程`lock()`时，会调用`tryAcquire()`独占该锁并将 state+1。
  * 此后，其他线程再`tryAcquire()`时就会失败，直到A线程`unlock()`到state=0（即释放锁）为止，其它线程才有机会获取该锁。
  * 当然，释放锁之前， A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。
  * 但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零的。

* **再以 CountDownLatch 以例**：
  * 任务分为 N 个子线程去执行， state也初始化为N（注意N要与线程个数⼀致）。
  * 这 N 个子线程是并行执行的，每个子线程执行完后 `countDown()` ⼀次， `state-1` （CAS）。
  * 等到所有子线程都执行完后(即state=0)，会`unpark()`主调用线程，然后主调用线程就会从`await()`函数返回，继续后续动作。

### AQS：ReentrantLock :exclamation::exclamation::exclamation:

传送门：[Java：AQS 小记-2(ReentrantLock)](https://www.cnblogs.com/zhuchengchao/p/14800883.html)

### AQS：信号量 & 倒计时器 & 循环栅栏 :exclamation:

* **Semaphore / 信号量**：允许多个线程同时访问，synchronized 和 ReentrantLock 都是⼀次只允许⼀个线程访问某个资源， Semaphore 可以指定多个线程同时访问某个资源。

  > 信号量主要用于两个目的：
  >
  > - **一个是用于共享资源的互斥使用**
  > - **另一个用于并发线程数的控制**
  >
  > 通过 `new Semaphore(3);` 来指定允许访问线程数，通过 `acquire()` 来获取信号量，通过 `release();` 来释放许可
  >
  > * `acquire`：通过该方法获取到一个许可，然后对共享资源进行操作；如果许可已经分配完了，那么线程将进入等待状态，直到其他线程释放许可才有机会再次获得许可；
  > * `release`：线程释放一个许可，许可将被归还给 Semaphore

* **CountDownLatch / 倒计时器**：CountDownLatch 是⼀个同步工具类，用来**协调多个线程之间的同步**。这个工具通常**用来控制线程等待**，它可以**让某⼀个线程等待直到倒计时结束**，在开始执行。其通过一个计数器来实现，计数器的初值是线程的数量，当每一个线程执行完成后，计数器的值-1，当计数器的值为 0 时，表示所有其他线程都执行完毕，**等待的线程继续执行**。

  > 关键方法：
  >
  > - `await`：调用该方法的线程会被挂起，直到 count 的值为 0 时才继续执行；
  > - `countDown`：将 count 值减 1

* **CyclicBarrier / 循环栅栏**：CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的计数等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。

  CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，**让⼀组线程到达⼀个屏障（也可以叫同步点）时被阻塞，直到最后⼀个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活**。CyclicBarrier 默认的构造方法是 `CyclicBarrier(int parties)`，其参数表示屏障拦截的线程数量，每个线程调用 `await()`方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 
  
  > 其他：CountDownLatch 基于 AQS 的共享模式；CyclicBarrier 基于 Condition 实现

### 同步容器和并发容器

同步集合与并发集合都为多线程和并发提供了合适的线程安全的集和，不过并发集合的可扩展性更高。

**同步容器**：

* 可以简单地理解为通过 synchronized 来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。
* 同步容器有：遗留的线程安全集合如 `Hashtable` ， `Vector`
* 使用 `Collections` 装饰的线程安全集合，如：
  * `Collections.synchronizedCollection/synchronizedList/synchronizedMap/synchronizedSet`

**并发容器**：

* 并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性

* 在 ConcurrentHashMap 中采用了一种粒度更细的加锁机制


**同步容器SynchronizedMap 和 并发容器ConcurrentHashMap 单独比较：**

* SynchronizedMap：一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为 map。

* ConcurrentHashMap 使用分段锁（JDK 7）来保证在多线程下的性能

  * ConcurrentHashMap 中则是一次锁住一个桶。ConcurrentHashMap 默认将hash 表分为 16 个桶，诸如 get、put、remove 等常用操作只锁当前需要用到的桶。这样，原来只能一个线程进入，现在却能同时有 16 个写线程执行，并发性能的提升是显而易见的。

  * 另外 ConcurrentHashMap 使用了一种**不同的迭代方式**。在这种迭代方式中，当 iterator 被创建后集合再发生改变就不再是抛出 `ConcurrentModificationException`（**fail-fast机制**），取而代之的是在改变时 new 新的数据从而不影响原有的数据 ，iterator 完成后再将头指针替换为新的数据 ，这样 iterator 线程可以使用原来老的数据，而写线程也可以并发的完成改变

    即：**当集合的结构被改变的时候，fail-safe 机制会在复制原集合的一份数据出来**，然后在复制的那份数据遍历，这就是**fast-safe机制**

### 关于 CopyOnWriteArrayList

CopyOnWriteArrayList：写时复制，主要是一种**读写分离的思想**

写时复制，CopyOnWrite 容器即写时复制的容器，往一个容器中添加元素的时候，不直接往当前容器 `Object[]` 添加，而是先将 `Object[]` 进行 copy，复制出一个新的容器 `object[] newElements`，然后新的容器 `Object[] newElements` 里添加元素，添加元素完后，在将原容器的引用指向新的容器 `setArray(newElements);` 这样做的**好处是可以对 copyOnWrite 容器进行并发的读，而不需要加锁**，因为当前容器不需要添加任何元素。

所以 CopyOnWrite 容器也是一种读写分离的思想，读和写不同的容器，就是写的时候，把 ArrayList 扩容一个出来，然后把值填写上去，再通知其他的线程，把 ArrayList 的引用指向扩容后的容器。

* 适合『读多写少』的应用场景 
* **get 弱一致性**
* **迭代器弱一致性**

> 不要觉得弱一致性就不好
>
> - 数据库的 MVCC 都是弱一致性的表现
> - 并发高和一致性是矛盾的，需要权衡 

### 阻塞队列 :exclamation::exclamation:

阻塞队列（BlockingQueue）是一个**支持两个附加操作的队列**，这两个附加的操作是：

* **在队列为空时，获取元素的线程会等待队列变为非空，即获取元素的线程会被阻塞；**
* **当队列满时，存储元素的线程会等待队列可用，即往队列中添加元素的线程会被阻塞；**

阻塞队列常用于**生产者和消费者**的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

> 代码可见：[手撕代码：消费者生产者]()

**为什么要用阻塞队列？**

使用阻塞队列的好处是我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切 BlockingQueue 都帮你一手包办了

在 concurrent 包发布以前，在多线程环境下，我们每个程序员都必须自己取控制这些细节（使用wait/notify/notifiAll/synchronize），尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。

BlockingQueue 阻塞队列是属于一个接口，底下有七个实现类

- **ArrayBlockQueue**：由数组结构组成的有界阻塞队列

- **LinkedBlockingQueue**：由链表结构组成的有界（但是默认大小 Integer.MAX_VALUE）的阻塞队列

  > 有界，但是界限非常大，相当于无界，可以当成无界

- PriorityBlockQueue：支持优先级排序的无界阻塞队列

- DelayQueue：使用优先级队列实现的延迟无界阻塞队列

- **SynchronousQueue**：不存储元素的阻塞队列，也即单个元素的队列

  > 生产一个，消费一个，不存储元素，不消费不生产

- LinkedTransferQueue：由链表结构组成的无界阻塞队列

- LinkedBlockingDeque：由链表结构组成的双向阻塞队列

> 更加详细内容可见对应的阻塞队列笔记