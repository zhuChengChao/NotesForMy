# 面经：4-集合类

> 个人整理 :muscle: 个人专用 :muscle: 暑期实习 :muscle: 秋招 :muscle: 后端开发 :muscle: 八股文 :no_mouth:

### 常用的容器 :exclamation::exclamation::exclamation:

常见容器主要包括 Collection 和 Map 两种，**Collection 存储着对象的集合**，而 **Map 存储着键值对（两个对象）的映射表**。

<img src="https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808516.PNG" alt="Collection" style="zoom: 67%;" />

<img src="https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251817101.PNG" alt="Map" style="zoom:67%;" />

**Collection**

- **Set**

  | Set           | 说明                                                         |
  | ------------- | ------------------------------------------------------------ |
  | HashSet       | 基于哈希表(HashMap)实现，支持快速查找，但不支持有序性操作。<br />并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的 |
  | LinkedHashSet | 具有 HashSet 的查找效率，底层是**链表+哈希表**。<br />使用哈希表存储元素，再维护一个**双向链表**保存元素的插入信息 |
  | TreeSet       | **基于红黑树实现**，支持有序性操作；<br />例如：根据一个范围查找元素的操作。<br />但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN) |

- **List**

  | List       | 说明                                                         |
  | ---------- | ------------------------------------------------------------ |
  | ArrayList  | 基于**动态数组**实现，支持随机访问，1.5倍扩容                |
  | Vector     | 和 ArrayList 类似，但它是**线程安全**的，2倍扩容             |
  | LinkedList | 基于**双向链表实现**，只能顺序访问，但是可以快速地在链表中间插入和删除元素。<br />不仅如此，LinkedList 还可以用作栈、队列和双向队列 |

- **Queue**

  | Queue         | 说明                                                         |
  | ------------- | ------------------------------------------------------------ |
  | LinkedList    | 基于链表实现的队列，可以用它来实现双向队列                   |
  | PriorityQueue | **基于堆结构**实现，可以用它来实现优先队列                   |
  | ArrayDeque    | 实现了 Deque（双向队列），Deque 继承自 Queue<br />使用了可变数组，可以做为队列来使用，也可以作为栈使用<br />ArrayDeque不支持`null`值 |

**Map**

| Map           | 说明                                                         |
| ------------- | ------------------------------------------------------------ |
| HashMap       | 基于哈希表实现                                               |
| LinkedHashMap | 使用双向链表来维护元素的顺序，**顺序为插入顺序或者最近最少使用（LRU，Least Recently Used）顺序** |
| TreeMap       | 基于**红黑树**实现                                           |
| HashTable     | 和 HashMap 类似，但它是**线程安全**的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致<br />它是**遗留类**，不应该去使用它<br />现在可以使用 ConcurrentHashMap 来支持线程安全，其效率会更高，因为引入了分段锁（JDK 7） |

> 参考：
>
> https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### List & Set & Map 的区别

* **List(对付顺序的好帮手)**：List 接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象 
* **Set(注重独一无二的性质)**：不允许重复的集合。不会有多个元素引用相同的对象。 
* **Map(用Key来搜索的专家)**：使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。 

| 比较       | LIst                                                         | Set                                                          | Map                                                          |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 继承接口   | Collection                                                   | Collection                                                   | 是个接口                                                     |
| 常见实现类 | AbstractList<br />常用的子类有：<br />ArrayList<br />LinkedList<br />Vector | AbstractSet<br />常用的子类有：<br />HashSet<br />LinkedHashSet<br />TreeSet | 实现的类：<br />HashMap<br />HashTable<br />LinkedHashMap    |
| 常见方法   | add()<br />remove()<br />clear()<br />get()<br />contains()<br />size()<br />... | add()<br />remove()<br />clear()<br />get()<br />contains()<br />size()<br />... | put()<br />get()<br />remove()<br />clear()<br />containsKey()<br />containsValue()<br />keySet()<br />values()<br />size()<br />... |
| 元素       | 可重复                                                       | 不可重复                                                     | 不可重复                                                     |
| 顺序       | 有序                                                         | 一般无序(由hashcode决定)                                     | 一般无序                                                     |
| 线程安全   | Vector线程安全                                               |                                                              | HashTable线程安全                                            |

> 参考：
>
> https://blog.csdn.net/qq_41701956/article/details/103223461

### 如何选用集合

主要根据集合的特点来选用，比如我们需要**根据键值获取到元素值**时就选用 Map 接口下的集合；

* 需要排序时选择 TreeMap；
* 不需要排序时就选择 HashMap；
* 需要保证线程安全就选用 ConcurrentHashMap。

当我们**只需要存放元素值**时，就选择实现 Collection 接口的集合，需要保证元素唯一时选择实现 Set 接口的集合比如 TreeSet 或 HashSet，不需要就选择实现 List 接口的比如 ArrayList 或 LinkedList，然后再根据实现这些接口的集合的特点来选用。 

### ArrayList 和 LinkedList 的区别 :exclamation::exclamation::exclamation:

**ArrayList：**底层是基于**动态数组**实现的，查找快，增删较慢；

**LinkedList：**底层是基于链表实现的，查找慢，增删快；

* 确切的说是双向链表（JDK1.6 之前是双向循环链表、**JDK1.7 之后取消了循环**），查找慢、增删快。
* LinkedList 链表由一系列节点连接而成，一个节点包含 3 个部分：元素内容、前驱节点和后驱节点。
* 链表内部有一个 **first 节点**，为链表中的第一个元素；内部有一个 **last 节点**，为链表中的最后一个元素。

> **补充：**
>
> **ArrayList 的增删未必就是比 LinkedList 要慢：**
>
> 1. 如果增删都是在末尾来操作（每次调用的都是 `remove()` 和 `add()`），此时 ArrayList 就不需要移动和复制数组来进行操作了。如果数据量有百万级的时，速度是会比 LinkedList 要快的。
>
> 2. 如果删除操作的位置是在中间。由于 LinkedList 的消耗主要是在遍历上（ LinkedList 会比较查询的 index 与链表长度，选择从头还是从尾开始查找），ArrayList 的消耗主要是在移动和复制上（底层调用的是 `arrayCopy()` 方法，是 native 方法）。LinkedList 的遍历速度是要慢于 ArrayList 的复制移动速度的，如果数据量有百万级的时，还是 ArrayList 要快。
>
>    ```java
>    // ArrayList
>    public void add(int index, E element) {
>        rangeCheckForAdd(index);
>                   
>        ensureCapacityInternal(size + 1);  // Increments modCount!!
>        System.arraycopy(elementData, index, elementData, index + 1,
>                         size - index);
>        elementData[index] = element;
>        size++;
>    }
>                   
>    // LinkedList比较需要插入的 index 与链表长度
>    // 小于链表长度一般则从而开始遍历，反之从尾开始遍历
>    Node<E> node(int index) {
>        // assert isElementIndex(index);
>                   
>        if (index < (size >> 1)) {   // 小于链表长度的一半，则从头开始遍历
>            Node<E> x = first;  // first节点
>            for (int i = 0; i < index; i++)
>                x = x.next;
>            return x;
>        } else {					// 大于链表长度的一半，则从末尾开始遍历
>            Node<E> x = last;  // last节点
>            for (int i = size - 1; i > index; i--)
>                x = x.prev;
>            return x;
>        }
>    }
>    ```
>
> > 参考：https://www.cnblogs.com/syp172654682/p/9817277.html

> 参考：https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### RandomAccess 接口

**ArrayList 实现 RandomAccess 接口有何作用？为何 LinkedList 却没实现这个接口？**

> ArrayList 实现了 RandomAccess
>
> ```java
> public class ArrayList<E> 
> 	extends AbstractList<E> 
> 	implements List<E>, RandomAccess, Cloneable, java.io.Serializable{
> 	// ...
> }
> ```
>
> LinkedList 未实现该接口
>
> ```java
> public class LinkedList<E>
>     extends AbstractSequentialList<E>
>     implements List<E>, Deque<E>, Cloneable, java.io.Serializable{
>     // ...
> }
> ```

1. RandomAccess 接口只是一个标志接口(Marker interface)，只要 List 集合实现这个接口，就能**支持快速随机访问**。

2. 通过查看 Collections 类中的 `copy()` 方法：

   ```java
   public static <T> void copy(List<? super T> dest, List<? extends T> src) {
       int srcSize = src.size();
       if (srcSize > dest.size())
           throw new IndexOutOfBoundsException("Source does not fit in dest");
   
       if (srcSize < COPY_THRESHOLD ||
           (src instanceof RandomAccess && dest instanceof RandomAccess)) {
           // src与dest实现了RandomAccess接口，则用for循环遍历
           for (int i=0; i<srcSize; i++)
               dest.set(i, src.get(i));
       } else {
           // src 或 dest 有一没实现RandomAccess接口，则用iterator循环遍历
           ListIterator<? super T> di=dest.listIterator();
           ListIterator<? extends T> si=src.listIterator();
           for (int i=0; i<srcSize; i++) {
               di.next();
               di.set(si.next());
           }
       }
   }
   ```
   
   实现 RandomAccess 接口的 List 集合采用一般的 for 循环遍历，而未实现这接口则采用迭代器，即 ArrayList 一般采用 for 循环遍历，而 LinkedList 一般采用迭代器遍历；
   
3. 理由则为：**ArrayList 用 for 循环遍历比 iterator 迭代器遍历快，LinkedList 用 iterator 迭代器遍历比 for 循环遍历快。**所以说，当我们在做项目时，应该考虑到 List 集合的不同子类采用不同的遍历方式，能够提高性能。

> 参考：https://blog.csdn.net/weixin_39148512/article/details/79234817

### ArrayList 的扩容机制 :exclamation::exclamation:

> 更多关于ArrayList的内容可见：[Java：ArrayList类小记](https://www.cnblogs.com/zhuchengchao/p/14297634.html)

> 推荐阅读+参考：
>
> https://juejin.im/post/5d42ab5e5188255d691bc8d6
>
> https://www.cnblogs.com/SunArmy/p/9844022.html

**总的来说就是分两步：**

1. **扩容**：把原来的数组复制到另一个内存空间更大的数组中（1.5倍）
2. **添加元素**：把新元素添加到扩容以后的数组中

**分步说明：**

1. 当使用 add 方法的时候首先调用 ensureCapacityInternal 方法，传入 size+1 进去，检查是否需要扩充 elementData 数组的大小；

   ```java
   // 1.ArrayList中的add方法
   public boolean add(E e) {
       // 因为要添加元素，所以添加之后可能导致容量不够，所以需要在添加之前进行判断（扩容）
       ensureCapacityInternal(size + 1);  // Increments modCount!!
       // 最后扩容成功/不需要扩容  才添加元素，并令size+1
       elementData[size++] = e;
       return true;
   }
   
   // 2.ArrayList 中 add 方法的 ensureCapacityInternal 方法
   private void ensureCapacityInternal(int minCapacity) {
       ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
   }
   
   // 3.calculateCapacity方法：
   // 判断传入的数组是否为空，若是，则返回DEFAULT_CAPACITY与minCapacity中的最大值
   private static int calculateCapacity(Object[] elementData, int minCapacity) {
       // 其中，DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};
       // 满足下面条件表示的是第一次添加元素需要的扩容操作
       if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
           // 其中private static final int DEFAULT_CAPACITY = 10;
           return Math.max(DEFAULT_CAPACITY, minCapacity);
       }
       return minCapacity;
   }
   
   // 4.ensureExplicitCapacity方法：
   // 判断添加元素后的数组，是否可能发生溢出，若可能发生溢出，则进行grow扩容
   private void ensureExplicitCapacity(int minCapacity) {
       modCount++;  // 涉及 fail-fast
   
       // overflow-conscious code 已经溢出了 需要扩容了
       if (minCapacity - elementData.length > 0)
           grow(minCapacity);
   }
   ```

2. 当需要扩容，即已经发生了溢出，则调用grow函数进行扩容操作

   ```java
   private void grow(int minCapacity) {
       // overflow-conscious code
       int oldCapacity = elementData.length;
       // 扩容大小为原数组长度的1.5倍；
       int newCapacity = oldCapacity + (oldCapacity >> 1);
       // 检查新容量的大小是否小于最小需要容量，如果小于那就将最小容量最为数组的新容量
       // 这是考虑到第一次进入时，oldCapacity为0的情况
       if (newCapacity - minCapacity < 0)
           newCapacity = minCapacity;
       // 当新容量大于MAX_ARRAY_SIZE，使用hugeCapacity比较二者
       if (newCapacity - MAX_ARRAY_SIZE > 0)
           newCapacity = hugeCapacity(minCapacity);
       // minCapacity is usually close to size, so this is a win:
       elementData = Arrays.copyOf(elementData, newCapacity);
   }
   ```

   `newCapacity = oldCapacity + (oldCapacity >> 1);`扩容大小为原数组长度的1.5倍；

   `newCapacity - MAX_ARRAY_SIZE`当新容量大于MAX_ARRAY_SIZE，使用hugeCapacity比较二者

   ```java
   private static int hugeCapacity(int minCapacity) {
       if (minCapacity < 0) // overflow
           throw new OutOfMemoryError();
       // 对minCapacity和MAX_ARRAY_SIZE进行比较
       // 若minCapacity大，将Integer.MAX_VALUE作为新数组的大小
       // 若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小
       // MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
       return (minCapacity > MAX_ARRAY_SIZE) ?
           Integer.MAX_VALUE :
       MAX_ARRAY_SIZE;
   }
   ```

3. ArrayList 中 copy 数组的核心就是 `System.arraycopy` 方法，将 original 数组的所有数据复制到 copy 数组中，这是一个本地方法。

   ```java
   // 在grow函数中最终调用Arrays.copyOf方法
   elementData = Arrays.copyOf(elementData, newCapacity);
   
   // 进一步：Arrays.copyOf 调用流程
   // 1.Arrays类中的copyOf方法：
   @SuppressWarnings("unchecked")
   public static <T> T[] copyOf(T[] original, int newLength) {
       return (T[]) copyOf(original, newLength, original.getClass());
   }
   
   // 2.Arrays类中的copyOf方法：
   public static <T,U> T[] copyOf(U[] original, int newLength, Class<? extends T[]> newType) {
       @SuppressWarnings("unchecked")
       T[] copy = ((Object)newType == (Object)Object[].class)
           ? (T[]) new Object[newLength]
           : (T[]) Array.newInstance(newType.getComponentType(), newLength);
       System.arraycopy(original, 0, copy, 0,
                        Math.min(original.length, newLength));
       return copy;
   }
   
   // 3. System类中的arraycopy方法：是一个native方法
   public static native void arraycopy(Object src,  int  srcPos,
                                       Object dest, int destPos,
                                       int length);
   ```

### Array 和 ArrayList 区别 :exclamation::exclamation:

1. Array（数组） 可以容纳基本类型和对象，而 ArrayList 只能容纳对象，但是 Array 数组在存放的时候一定是同种类型的元素，而 ArrayList 就不一定了，因为 ArrayList 可以存储 Object；
2. Array 大小是固定的，ArrayList 的大小是动态变化的（底层基于动态数组，可以进行扩容操作）。

**什么时候更适合使用 Array：**

1. 如果**列表的大小已经指定**，大部分情况下是存储和遍历它们；
2. 对于遍历**基本数据类型**，尽管 Collections 使用自动装箱来减轻编码任务，在指定大小的基本类型的列表上工作也会变得很慢；
3. 如果你要使用多维数组，使用 `[][]` 比`<List>` 更容易。

> 参考：https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### HashMap 的数据结构 :exclamation::exclamation::exclamation:

> 更为详细的内容可见博客章节：[Java：HashMap类小记](https://www.cnblogs.com/zhuchengchao/p/14298141.html)

HashMap 的实现可分为 JDK7 与 JDK8 两个版本，JDK1.7 和 1.8 的主要区别在于**头插和尾插**方式的修改，头插容易导致 HashMap 链表死循环，并且 1.8 之后加入**红黑树**对性能有提升

> **HashMap 实现及原理分析**：https://www.cnblogs.com/chengxiao/p/6059914.html

**JDK1.7：Entry数组 + 链表**

HashMap 的主干是一个 Entry 数组。Entry 是 HashMap 的基本组成单元，每一个 Entry 包含一个 key-value 键值对。

```java
// HashMap的主干数组，可以看到就是一个Entry数组，初始值为空数组{}
// 且有：主干数组的长度一定是2的次幂，至于为什么这么做，参考文章中有详细分析
transient Entry<K,V>[] table = (Entry<K,V>[]) EMPTY_TABLE;
```

Entry 是 HashMap 中的一个静态内部类。代码如下：

```java
static class Entry<K,V> implements Map.Entry<K,V> {
    final K key;
    V value;
    Entry<K,V> next;  // 存储指向下一个Entry的引用，单链表结构
    int hash;         // 对key的hash值进行hash运算后得到的值，存储在Entry，避免重复计算
    
    // ... 构造函数/get/set/toString
}

// 插入节点：头插法
void createEntry(int hash, K key, V value, int bucketIndex) {
    // 取出索引位置的元素
    Entry<K,V> e = table[bucketIndex];
    // 将新的元素放置到索引位，同时将原来的作为新元素的下一个保存，形成单向链表
    // 头插法
    table[bucketIndex] = new Entry<>(hash, key, value, e);
    size++;
}
```

> **总结**：
>
> 简单来说：**HashMap 由数组+链表组成的**，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；
>
> 如果定位到的数组位置不含链表（当前entry的next指向null），那么对于查找，添加等操作很快，仅需一次寻址即可；
>
> 如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过 key 对象的 equals 方法逐一比对查找。
>
> 所以，性能考虑，HashMap中的链表出现越少，性能才会越好。

**JDK1.8：Node数组 + 链表/红黑树；**

> 进一步说明：
>
> 1. Node数组：这里变成了 Node 数组，而不是 Entry 数组了，Node 数组其实实现了 Entry 数组，见源码部分
> 2. 链表：单向链表
> 3. **红黑树：红黑树节点+双向链表**

Entry 和 Node 都包含 key、value、hash、next 属性，以下是 **Node 的源码**：

```java
// HashMap的主干数组
transient Node<K,V>[] table;

// Node类继承了 Map.Entry<K,V>
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    V value;
    Node<K,V> next;  // 指向下一个节点的指针
	
    // ... 构造函数 get/set/toString

    public final int hashCode() {
        // 注意这是获取Node的hash值
        // 操作：对key和value取了一个异或操作
        return Objects.hashCode(key) ^ Objects.hashCode(value);
    }

    public final V setValue(V newValue) {
        V oldValue = value;
        value = newValue;
        return oldValue;
    }

    public final boolean equals(Object o) {
        // 判断是否相等，同时对key和value进行判断
        if (o == this)
            return true;
        if (o instanceof Map.Entry) {
            Map.Entry<?,?> e = (Map.Entry<?,?>)o;
            if (Objects.equals(key, e.getKey()) &&
                Objects.equals(value, e.getValue()))
                return true;
        }
        return false;
    }
}
```

以下是**红黑树的节点类源码**：

```java
// 红黑树节点+双向链表，可见其继承了LinkedHashMap.Entry<K,V>
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
    TreeNode<K,V> parent;  // red-black tree links
    TreeNode<K,V> left;	   // 左子树
    TreeNode<K,V> right;   // 右子数
    TreeNode<K,V> prev;    // needed to unlink next upon deletion
    boolean red;
    TreeNode(int hash, K key, V val, Node<K,V> next) {
        super(hash, key, val, next);
    }
    
    // ...关于树的一些操作
}

// LinkedHashMap源码中：
// 红黑树中的双向链表就体现在此
// 而之所以在维护红黑树的同时，再维护了一个双向链表的结构，这是为了扩容方便
static class Entry<K,V> extends HashMap.Node<K,V> {
    Entry<K,V> before, after;  // 前一个和后一个节点
    Entry(int hash, K key, V value, Node<K,V> next) {
        super(hash, key, value, next);
    }
}
```

**转换为红黑树的条件**：

1. 当链表上的元素个数超过 8 个

   ```java
   // 判断链表长度到达8调用treeifyBin方法转换红黑树,TREEIFY_THRESHOLD的值为8
   // static final int TREEIFY_THRESHOLD = 8;
   if (binCount >= TREEIFY_THRESHOLD - 1)
       treeifyBin(tab, hash);
   ```

2. 在数组长度 >= 64 时才会转化成红黑树；

   ```java
   // treeifyBin方法开头有判断数组长度是否小于64,小于则进行扩容,否则转红黑树.
   // 其中:MIN_TREEIFY_CAPACITY的值为64.
   // static final int MIN_TREEIFY_CAPACITY = 64;
   final void treeifyBin(Node<K,V>[] tab, int hash) {
       int n, index; Node<K,V> e;
       if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
           resize();
       ...
   }
   ```

   > 参考：https://blog.csdn.net/g5zhu5896/article/details/82968287
   
3. 非树化什么时候进行？

   1. 树上的节点个数小于6；
   2. 仅在 resize 时，对树的迁移中进行了非树化的操作。

节点变成树节点，以提高搜索效率和插入效率到 O(logN)。

> 参考：https://blog.csdn.net/vking_wang/article/details/14166593

### HashMap 的 put() & get() :exclamation::exclamation::exclamation:

**put方法：**

1. 当我们想往一个 HashMap 中添加一对 key-value 时，系统**首先会计算 key 的 hash 值**；

   > hash 的计算公式：`(key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16)`，后续根据 `hash & (数组长度-1)` 计算在 hash表 中的位置

2. 拿到了 hash 值后，调用 `putVal(...)`，做了如下操作：
   1. 判断 table 是否为空，若为空，则调用 `resize()` 对 table 数组进行初始化；
   2. 根据 hash 值确认在 table 中存储的位置。若该位置没有元素，则直接插入；
   3. 若不为空，存在两种情况：
      1. 如果两个 hash 值相等且 key 值相等：则用新的 Entry 的 value 覆盖原来节点的 value；
      2. 发生了哈希冲突，再次分情况进行讨论：
         1. 若该链已经为树，则将该节点插入树中；
         2. 若该节点为链表，则插入到链表中，而当插入新节点后，若链表的长度过长(大于等于TREEIFY_THRESHOLD)，则将链表转化为红黑树结构。
         
         > 这部分内容见博客：[Java：HashMap类小记：HashMap 的 put&get 执行过程](https://www.cnblogs.com/zhuchengchao/p/14298141.html)

```java
public V put(K key, V value) {
    // 1. 通过hash(key)计算key的hash值
    // 2. 拿到了 hash 值后，调用 putVal()
    return putVal(hash(key), key, value, false, true);
}

// 1. 通过hash(key)计算key的hash值，
static final int hash(Object key) {
    int h;
    // 扰动避免算法，充分利用高低位
    // 其中：>>> 无符号右移，即高位补0
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

// 2. 拿到了hash值后，调用putVal()
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    // 定义辅助变量
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 2.1 判断table是否为空
    // hashmap对象中，若table属性为空->第一次put->resize()
    if ((tab = table) == null || (n = tab.length) == 0)
        // 调用resize函数，默认大小为16，对于resize函数后续分析☆
        n = (tab = resize()).length;
    // 2.2 发现tab[i]没有值，直接存入即可
    // 根据key的hash值计算该key在hashmap中的位置
    if ((p = tab[i = (n - 1) & hash]) == null)
        // 发现tab[i]没有值，则将元素放入table中
        tab[i] = newNode(hash, key, value, null);
    else {
        // 2.3 tab[i]取到值了，莫慌，先定义下方2个变量
        Node<K,V> e; K k;
        // 2.3.1 如果是key重复了，很简单，直接e = p，即value替换一下即可
        if (p.hash == hash &&  // 当前索引位置对应链表的头节点的hash值和待添加元素值相同
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 2.3.2 发生了hash冲突
        // 2.3.2.1 该链为树，则将该节点插入树中
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        // 2.3.2.2 该链为链表，则插入到链表中
        else {
            // 开始遍历链表
            for (int binCount = 0; ; ++binCount) {
                // 节点后已经没元素了，则插入
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // 添加完成后，判断是需要树化
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 遍历过程中判断节点key和待插入节点是否相同，满足则说明有重复key
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        // e不为空，说明产生了hash冲突，且存在了值的替换
        if (e != null) { // existing mapping for key
            V oldValue = e.value;  // 旧的value值返回
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;  // 新的值替换旧的值
            afterNodeAccess(e);  // 空方法，用于后续重写
            return oldValue;
        }
    }
    ++modCount;
    // 是否需要进行扩容
    if (++size > threshold)
        // 若需要扩容，则进行扩容操作，后续分析
        resize();
    afterNodeInsertion(evict);  // 空方法，用于后续重写
    return null;
}
```

**get方法：**

通过 key 的 hash 值找到在 table 数组中的索引处的 Node，然后返回该 key 对应的 value 即可。

在这里能够根据 key 快速的取到 value 除了和 HashMap 的数据结构密不可分外，还和 Node 有莫大的关系。

HashMap 在存储过程中并没有将 key，value 分开来存储，而是当做一个整体 key-value 来处理的，这个整体就是 Node 对象。

同时 value 也只相当于 key 的附属而已。

**即在存储的过程中，系统根据 key 的 HashCode 来决定 Node 在 table 数组中的存储位置`hash(key) & (数组长度-1)`），在取的过程中同样根据 key 的 HashCode 取出相对应的 Node 对象（value 就包含在里面）。**

```java
public V get(Object key) {
    Node<K,V> e;
    // 根据key找value，传入hash(key) 和 key
    // 根据返回结果，为null则直接返回，不然就返回e的value
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    // 如果表不是空的，并且要查找索引处有值
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        // 就判断位于第一个的key是否是要查找的key，即hash值相等的情况下，内容也要相同
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        // 说明第一个结点的值不相同，若结点后有链表/树继续遍历查找
        if ((e = first.next) != null) {
            // 如果不是就判断链表是否是红黑二叉树，如果是，就从树中取值
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            // 如果不是树，就遍历链表
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

> 参考：https://www.cnblogs.com/kangkaii/p/8473793.html

### HashMap 的 resize 方法 :exclamation::exclamation::exclamation:

> 更多关于 resize 的方法详解见个人博客：[Java：HashMap类小记：HashMap 的 resize/扩容](https://www.cnblogs.com/zhuchengchao/p/14298141.html)

**有两种情况会调用 resize 方法：**

1. 第一次调用 HashMap 的 put 方法时，会调用 resize 方法对 table 数组进行初始化，如果不传入指定值，默认大小为 16。

   ```java
   // hashmap对象中 tabel属性为空--->第一次put---->resize()
   if ((tab = table) == null || (n = tab.length) == 0)
       n = (tab = resize()).length;
   ```

2. 扩容时会调用 resize，即 size &gt; threshold 时，table 数组大小翻倍。

   ```java
   if (++size > threshold)
          resize();
   ```

   其中：`threshold=loadFactor * length`，也就是说数组长度固定以后， 如果负载因子越大，所能容纳的元素个数越多，如果超过这个值就会进行扩容(**默认是扩容为原来的2倍**)

   > 如果在一些特殊情况下，比如空间比较多，但要求速度比较快，这时候就可以把扩容因子调小以较少hash冲突的概率
   >
   > 相反就增大扩容因子(这个值可以大于1的，因为存在hash冲突，也很好理解)

**resize 文字说明**：

每次扩容之后容量都是**翻倍**。扩容后要将原数组中的所有元素找到在新数组中合适的位置。

有如下：当我们把 `table[i]` 位置的所有 `node` 迁移到 `newtab` 中去的时候：这里面的 `node` 要么在 `newtab` 的 `i` 位置（不变），要么在 `newtab` 的 `i + n` 位置。

> 其中 n 为 原table 的长度

也就是我们可以这样处理：把 `table[i]` 这个桶中的 `node` 拆分为两个链表 L1 和 L2：如果 `hash & n == 0`，那么当前这个 `node` 被连接到 L1 链表；否则连接到 L2 链表。这样下来，当遍历完 `table[i]` 处的所有 node 的时候，我们得到两个链表 L1 和 L2，这时我们令 `newtab[i] = L1`，`newtab[i + n] = L2`，这就完成了 `table[i]` 位置所有 node 的迁移（rehash），**这也是 HashMap 中容量一定的是 2 的整数次幂带来的方便之处**。

> 图解流程：扩容机制：https://www.cnblogs.com/duodushuduokanbao/p/9492952.html
>
> 我们使用的是 **2次幂** 的扩展(指长度扩为原来2倍)，所以，**元素的位置要么是在原位置，要么是在原位置再移动 2次幂 的位置**。
>
> 看下图可以明白这句话的意思，n为table的长度，图(a)表示扩容前的 key1 和 key2 两种 key 确定索引位置的示例，图(b)表示扩容后 key1 和 key2 两种 key 确定索引位置的示例，其中 hash1 是 key1 对应的哈希与高位运算结果。
>
> ![HashMap扩容1](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808642.png)
>
> 元素在重新计算 hash 之后，因为 n 变为 2 倍，那么 n-1 的 mask 范围在高位多1bit(红色)，因此新的 index 就会发生这样的变化：
>
> ![HashMap扩容2](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808093.png)
>
> 因此，我们在扩充 HashMap 的时候，不需要像 JDK1.7 的实现那样重新计算 hash，**只需要看看原来的 hash 值新增的那个 bit 是1还是0就好了**，是0的话索引没变，是1的话索引变成**“原索引+oldCap”**，可以看看下图为16扩充为32的resize示意图：
>
> ![HashMap扩容3](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808524.png)
>
> 这个设计确实非常的巧妙，既省去了重新计算 hash 值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此 resize 的过程，均匀的把之前的冲突的节点分散到新的 bucket 了。这一块就是 JDK1.8 新增的优化点。有一点注意区别，JDK1.7中 rehash 的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，**JDK1.8不会倒置**。

**resize 源码**：见博客内容吧[Java：HashMap类小记：HashMap 的 resize/扩容-resize详解 + 红黑树数据迁移split](https://www.cnblogs.com/zhuchengchao/p/14298141.html)

### HashMap 的 size 是 2 的整数次方 :exclamation::exclamation:

**总的来讲：是为了将 key 的 hash 值均匀的分布在数组的索引上，减少哈希冲突的出现。**

1. 这样做总是能够保证 HashMap 的底层数组长度为 2 的 n 次方。当 length 为 2 的 n 次方时，`hash(key)&(length-1)`  就相当于对 length 取模 `(hash(key)%length)`，而且速度比直接取模快得多，**这是 HashMap 在速度上的一个优化**。
2. 如果 length 为 2 的次幂，则 length - 1 转化为二进制必定是 `11111……` 的形式，在与 key 的hash值进行二进制进行与操作时效率会非常的快，而且**空间不浪费**。
3. 如果 length 不是 2 的次幂，比如：length 为 15，则 length - 1 为 14，对应的二进制为 `1110`，在于 key的hash 与操作，最后一位都为 0 ，而 `0001，0011，0101，1001，1011，0111，1101` 这几个位置永远都不能存放元素了，**空间浪费相当大**，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率，这样就会造成空间的浪费。
4. **便于扩容**：扩充 HashMap 的时候，不需重新计算 hash，只需要看看原来的 hash 值新增的那个 bit 是1还是0就好了，是0的话索引没变，是1的话索引变成**“原索引+oldCap”**，更为具体的可见上一问：**HashMap 的 resize 方法**

> 参考：
>
> https://blog.csdn.net/zjcjava/article/details/78495416
>
> https://www.cnblogs.com/zhimingxin/p/8609545.html

### HashMap 多线程死循环+数据丢失问题 :exclamation::exclamation:

**JDK7 下存在多线程死循环问题：**

主要是多线程同时 put 时，如果同时触发了 rehash 操作，会导致 HashMap 中的链表中出现 **循环节点**，进而使得后面再次 get 的时候，会**死循环**。

> 代码总结：在 resize 时，会进入一个 transfer 函数，当一个线程在在进行节点迁移时，失去了 CPU 的控制权，而导致另一个线程完成了扩容，再恢复之前的线程时就可能会出现链表的环状结构！

**详细说明：**

通过查看 JDK7 `put()` 、`addEntry()`、`resize()`、`transfer()`函数说明死循环出现过程

```java
public V put(K key, V value) {
    // HashMap允许存储null键，存储在数组的0索引位置
    if (key == null)
        // JDK7中通过 putForNullKey 函数来处理key为null
        return putForNullKey(value);
    // 内部通过一个扰乱算法获得一个hash值，用于计算数组索引
    int hash = hash(key);
    // 计算数组索引，找到那个hash桶的位置
    int i = indexFor(hash, table.length);
    // 判断是否是重复键
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }

    modCount++;
    // 添加元素
    addEntry(hash, key, value, i);
    return null;
}

// 添加新节点
void addEntry(int hash, K key, V value, int bucketIndex) {
    // 元素个数大于阈值，同时当前索引位有值，就会执行扩容操作
    if ((size >= threshold) && (null != table[bucketIndex])) {
        // 2倍扩容，这里就会出现线程安全问题！！！
        resize(2 * table.length);
        hash = (null != key) ? hash(key) : 0;
        // 重新计算索引位置
        bucketIndex = indexFor(hash, table.length);
    }
	// 基于键值创建Entry节点，并以头插法存入对应位置，在扩容之后再添加数据
    createEntry(hash, key, value, bucketIndex);
}

// 需要经过扩容
void resize(int newCapacity) {
    Entry[] oldTable = table;
    int oldCapacity = oldTable.length;
    // 达到最大容量，不扩容
    if (oldCapacity == MAXIMUM_CAPACITY) {
        threshold = Integer.MAX_VALUE;
        return;
    }
    // 根据新容量创建数组
    Entry[] newTable = new Entry[newCapacity];
    boolean oldAltHashing = useAltHashing;
    useAltHashing |= sun.misc.VM.isBooted() &&
            (newCapacity >= Holder.ALTERNATIVE_HASHING_THRESHOLD);
    // 计算是否需要重新计算hash
    boolean rehash = oldAltHashing ^ useAltHashing;
    // 将旧数组中的元素迁移到新的数组中
    transfer(newTable, rehash);
    // 保存新数组
    table = newTable;
    threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);
}

// ☆1：扩容过程中当然涉及到了节点的转移操作
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    // 遍历数据的每一个角标位
    for (Entry<K,V> e : table) {
        // 当数组对应的桶位置不为null，则需要进行数据迁移
        while(null != e) {
            // ☆2：记录遍历到的元素的下一个元素
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            // 计算新数组的角标位置，有两种情况：在原先位置 / 原位置+原长度
            int i = indexFor(e.hash, newCapacity);
            // ☆5.把当前元素的下一个改为新数组对应位置的元素--头插法
            e.next = newTable[i];
            // 将当前元素放置在数组对应索引位置
            newTable[i] = e;
            // 再次迁移下一个元素
            e = next;
        }
    }
}
```

**结合上述代码进行文字+图片说明**：

1. 假定 thread-1, thread-2 都进入了 `transfer()` 函数进行扩容时的数据迁移工作，假定此时的 table 结构如下：

   ![resize造成死循环1](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808622.PNG)

2. 当 thread-1 执行完 `Entry<K,V> next = e.next;`后失去的 CPU 的使用权，现在 thread-1 的状态就是上面的状态；

3. thread-2 获取 CPU 的执行权，也进入这里执行，起始状态也是上图所示；

4. thread-2 执行后续逻辑完成扩容，最终结果如下（头插法）：

   ![resize造成死循环2](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808074.PNG)

5. thead-1 再次获取CPU的执行权，此时 e 和 next 的节点指向恢复，然后继续到 `e.next = newTable[i];`

   ![resize造成死循环3](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808499.PNG)

6. 当 thread-1 执行完 `e.next = newTable[i];`后存在如下结构，即存在了环状结构

   ![resize造成死循环4](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251808001.PNG)



**JDK8 下存在数据丢失问题：**

不过，JDK 1.8 后解决了多线程死循环问题（不适用头插法），但是还是不建议在多线程下使用 HashMap，因为多线程下使用 HashMap 还是会存在其他问题比如**数据丢失**。并发环境下推荐使用 ConcurrentHashMap。 

```java
// 添加元素时，会有数据覆盖丢失数据
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 此处，如果多个线程向同一个位置存入元素，会有值覆盖的问题，导致数丢失
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);

    // 下面代码省略
}

// resize函数中：扩容时，迁移数据的情况下，会有数据覆盖丢失的问题
// 多线程环境下，给同一个数组的相同位置赋值，会有数据覆盖的风险
if (loTail != null) {
    loTail.next = null;
    newTab[j] = loHead;  // 将原始索引位的数据迁移到新数组
}
if (hiTail != null) {
    hiTail.next = null;
    newTab[j + oldCap] = hiHead; // 将新索引位的数据迁移到新数组
}
```

> 详细请阅读个人博客部分：[Java：HashMap类小记：HashMap 多线程下的问题](https://www.cnblogs.com/zhuchengchao/p/14298141.html)

### HashMap 与 HashTable 的区别 :exclamation::exclamation:

**总结**：

HashTable 和 HashMap 的实现原理几乎一样，最主要的差别无非是：

1. HashTable 不允许 key 和 value 为 null；

2. **HashTable 是线程安全的**

   但是 HashTable 线程安全的策略实现代价却太大了，简单粗暴，**get/put 所有相关操作都是 synchronized 的**，这相当于给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。

**相同点：**

1. 都可以用来存储键值对
2. 底层哈希表结构查询速度都很快
3. 内部通过单链表解决冲突问题，容量不足会自动增加
4. 都实现了 Map 接口
5. 都实现了 Serializable 接口，支持序列化
6. 实现了 Cloneable 接口，可以被克隆

**不同点：**

1. 继承体系：**HashTable 基于 Dictionary 类**，而 **HashMap 是基于 AbstractMap**。

   Dictionary 是任何可将键映射到相应值的类的抽象父类；而 AbstractMap 是基于 Map 接口的实现，它以最大限度地减少实现此接口所需的工作。

   ```java
   public class HashMap<K,V> extends AbstractMap<K,V>
       implements Map<K,V>, Cloneable, Serializable {
   	...
   }
   public abstract class AbstractMap<K,V> implements Map<K,V> {
   	...
   }
   
   /**********************分割线**************************/
   
   public class Hashtable<K,V>
       extends Dictionary<K,V>
       implements Map<K,V>, Cloneable, java.io.Serializable {
       ...
   }
   
   public abstract class Dictionary<K,V> {
       ...
   }
   ```

   > 据说这是因为：历史原因

2. **线程安全不一样：**Hashtable 是线程安全的，而 HashMap 不是线程安全的，但是我们也可以通过 `Collections.synchronizedMap(hashMap)`，使其实现同步。

   ```java
   // 这是Hashtable的put()方法:synchronized加锁了
   public synchronized V put(K key, V value){
       ...
   }
   
   /************************************************/
   
   // 这是HashMap的put()方法:没用通过synchronized加锁
   public V put(K key, V value) {
       ...
   }
   ```

3. **HashMap 的 key 和 value 都允许为 null，而 Hashtable 的 key 和 value 都不允许为 null。**

   HashMap 遇到 key 为 null 的时候，在 hash 函数中做了对应的判断，将 null 修改为 0，而对 value 没有处理；

   Hashtable 遇到 null，直接返回 `NullPointerException`

   ```java
   // HashMap在put值时，在计算key的hash值时有null的判断
   public V put(K key, V value) {
       return putVal(hash(key), key, value, false, true);
   }
   
   // 在 hash(key)方法中：对于null做了特殊的处理
   static final int hash(Object key) {
       int h;
       return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
   }
   
   /**********************分割线**************************/
   
   // Hashtable
   public synchronized V put(K key, V value) {
       // Make sure the value is not null 
       // 1.值为null直接抛出异常
       if (value == null) {
           throw new NullPointerException();
       }
       // Makes sure the key is not already in the hashtable.
       Entry<?,?> tab[] = table;
       // 由于key是null，null当然是没有hashCode()这种方法的
       // 因此上述需要直接抛出异常NullPointerException
       int hash = key.hashCode();  
       int index = (hash & 0x7FFFFFFF) % tab.length;
       // ....
   }
   ```

   因此可以得出：**HashMap 的 get 方法不能否判断某个元素是否在 map 中**，因为 get 返回 null 有可能是不包含该 key，也有可能该 key 对应的 value 为 null。**因为 HashMap 中允许 key 为 null，也允许 value 为 null。**

4. **遍历方式的内部实现上不同**：HashMap 使用 Iterator 遍历，HashTable 使用 Enumeration 遍历；

   > 据说这也是因为：历史原因

5. HashMap 和 HashTable 的**初始化方式**和**扩容方式**不同

   HashMap：在构造函数中**不创建数组**，而是在第一次 put 时才创建，且初始大小为16；之后每次扩充容量为原来的两倍；

   **HashTable：在构造函数直接创建hashtable，且其初始大小为11，之后每次扩充2n+1**

   ```java
   // hashmap初始化:HashMap hashMap = new HashMap();
   // 默认构造函数
   public HashMap() {
       // 先不创建，在使用的时候再创建
       this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
       // 其中：DEFAULT_LOAD_FACTOR = 0.75f;
       // DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
   }
   
   public HashMap(int initialCapacity) {
       this(initialCapacity, DEFAULT_LOAD_FACTOR);
       // 调用方法：public HashMap(int initialCapacity, float loadFactor){}
       // 上述方法并不创建真正的数组，而是等到第一次put时才通过resize去创建
   }
   
   /**********************分割线**************************/
   
   // hashtable初始化:Hashtable hashtable = new Hashtable();
   public Hashtable() {
       // 构造函数直接创建hashtable
       this(11, 0.75f);
   }
   
   public Hashtable(int initialCapacity, float loadFactor) {
       if (initialCapacity < 0)
           throw new IllegalArgumentException("Illegal Capacity: "+
                                              initialCapacity);
       if (loadFactor <= 0 || Float.isNaN(loadFactor))
           throw new IllegalArgumentException("Illegal Load: "+loadFactor);
   
       if (initialCapacity==0)
           initialCapacity = 1;
       this.loadFactor = loadFactor;
       // 始化table，获得大小为initialCapacity的table数组
       table = new Entry<?,?>[initialCapacity];
       // 计算阀值
       threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1);
   }
   
   // hastable扩容分析：
   public synchronized V put(K key, V value) {
       // Make sure the value is not null
       if (value == null) {
           // 判断value是否为null
           throw new NullPointerException();
       }
   
       // Makes sure the key is not already in the hashtable.
       Entry<?,?> tab[] = table;
       // key若为null也会抛出异常
       int hash = key.hashCode();
       // 计算key在hash表中的位置
       int index = (hash & 0x7FFFFFFF) % tab.length;
       @SuppressWarnings("unchecked")
       Entry<K,V> entry = (Entry<K,V>)tab[index];
       // entry为null，表示还没有在hash表中添加过元素，需要去添加
       // entry不为null，表示发生了hash冲突，则遍历链表找到插入的位置
       for(; entry != null ; entry = entry.next) {
           if ((entry.hash == hash) && entry.key.equals(key)) {
               // key已经存在了，则替换一下value，然后返回oldvalue
               V old = entry.value;
               entry.value = value;
               return old;
           }
       }
   	
       // 添加元素，见下面
       addEntry(hash, key, value, index);
       return null;
   }
   
   private void addEntry(int hash, K key, V value, int index) {
       modCount++;
   
       Entry<?,?> tab[] = table;
       // 对容量进行检验，若大于阈值，则需要进行扩容操作，见下面
       if (count >= threshold) {
           // Rehash the table if the threshold is exceeded
           rehash();
   
           tab = table;
           hash = key.hashCode();
           index = (hash & 0x7FFFFFFF) % tab.length;
       }
   	
       // Creates the new entry.
       @SuppressWarnings("unchecked")
       // 添加元素
       Entry<K,V> e = (Entry<K,V>) tab[index];
       tab[index] = new Entry<>(hash, key, value, e);
       count++;
   }
   
   // rehash，扩容操作
   protected void rehash() {
       int oldCapacity = table.length;
       Entry<?,?>[] oldMap = table;
   
       // overflow-conscious code
       // 这里：新容量=旧容量 * 2 + 1
       int newCapacity = (oldCapacity << 1) + 1;
       if (newCapacity - MAX_ARRAY_SIZE > 0) {
           if (oldCapacity == MAX_ARRAY_SIZE)
               // Keep running with MAX_ARRAY_SIZE buckets
               return;
           newCapacity = MAX_ARRAY_SIZE;
       }
       // 新建一个size = newCapacity 的HashTable
       Entry<?,?>[] newMap = new Entry<?,?>[newCapacity];
   
       modCount++;
       // 重新计算阀值
       threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1);
       table = newMap;
   
       for (int i = oldCapacity ; i-- > 0 ;) {
           for (Entry<K,V> old = (Entry<K,V>)oldMap[i] ; old != null ; ) {
               Entry<K,V> e = old;
               old = old.next;
               int index = (e.hash & 0x7FFFFFFF) % newCapacity;
               e.next = (Entry<K,V>)newMap[index];
               newMap[index] = e;
           }
       }
   }
   ```

> 参考：
>
> https://blog.csdn.net/u010983881/article/details/49762595
>
> https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### HashTable 与 ConcurrentHashMap 的区别 :exclamation::exclamation:

**HashTable 和 ConcurrentHashMap 的区别：**

> 这里是按照 JDK7 对 ConcurrentHashMap 进行了分析，后续在关于 ConcurrentHashMap 分析中，会提到 JDK8 的优化

HashTable 和 ConcurrentHashMap 相比，**效率低**。 Hashtable 之所以效率低主要是使用了 synchronized 关键字对 put 等操作进行加锁，而 synchronized 关键字加锁是对整张 Hash 表的，即每次锁住整张表让线程**独占**，致使效率低下；

而 ConcurrentHashMap 采用**锁分段技术**，将整个 Hash 桶进行了分段 Segment，也就是将这个大的数组分成了几个小的片段 Segment，而每个小的片段 Segment 上面都有锁存在，那么在插入元素的时候就需要先找到应该插入到哪一个片段 Segment ，然后对该 Segment 加锁即可，这样做明显减小了锁的粒度，因此， ConcurrentHashMap 在多线程并发编程中可以实现多线程 put 操作。

![ConcurrentHashMap分段锁](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251809333.JPG)

**总结：**

ConcurrentHashMap 的出现也意味着 HashTable 的落幕，所以在以后的项目中，尽量少用 HashTable；

对于普通场景可以使用 HashMap 实现，如果是高并发场景建议使用 ConcurrentHashMap 实现

> 参考：
>
> https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg
>
> http://www.apgblogs.com/hashmap-hashtable-concurrenthashmap/

### ConcurrentHashMap 的实现原理 :exclamation::exclamation::exclamation:

> 这里仅进行一个简单的说明，如需详细了解：见博客
>
> - [Java：ConcurrentHashMap类小记-2(JDK7)](https://www.cnblogs.com/zhuchengchao/p/14758479.html)
> - [Java：ConcurrentHashMap类小记-3(JDK8)](https://www.cnblogs.com/zhuchengchao/p/14758491.html)

**数据结构**：

* JDK 7：中 ConcurrentHashMap 采用了 **数组 + Segment + 分段锁** 的方式实现。

* JDK 8：中 ConcurrentHashMap 参考了 JDK 8 HashMap 的实现，采用了 **数组 + 链表/红黑树** 的实现方式来设计，**内部大量采用 CAS 操作**。

**实现线程安全的方式：**

* **JDK 7：**

  ConcurrentHashMap 采用了非常精妙的"**分段锁"策略**，ConcurrentHashMap 的主干是个 Segment 数组。

  ```java
  final Segment<K,V>[]  segments;
  ```

  Segment 继承了 **ReentrantLock**，所以它就是一种可重入锁（ReentrantLock)。在 ConcurrentHashMap，一个 Segment 就是一个子哈希表，**Segment 里维护了一个 HashEntry 数组**，并发环境下，对于不同 Segment 的数据进行操作是不用考虑锁竞争的。就按默认的 ConcurrentLevel 为 16 来讲，理论上就允许 16 个线程并发执行。

  所以，对于同一个 Segment 的操作才需考虑线程同步，不同的 Segment 则无需考虑。Segment 类似于 HashMap，一个 Segment 维护着一个HashEntry 数组：

  ```java
  transient volatile HashEntry<K,V>[] table;
  ```

  HashEntry 是目前我们提到的最小的逻辑处理单元了。**一个 ConcurrentHashMap 维护一个 Segment 数组，一个 Segment 维护一个 HashEntry 数组。**因此，ConcurrentHashMap 定位一个元素的过程需要进行两次 Hash 操作。第一次 Hash 定位到 Segment，第二次 Hash 定位到元素所在的链表的头部。

* **JDK8 ：**

  ```java
  // 所有数据都存在table中, 只有当第一次插入时才会被加载，扩容时总是以2的倍数进行
  transient volatile Node<K,V>[] table;
  // 在扩容时存放变量，结束后置为null
  private transient volatile Node<K,V>[] nextTable;
  // 以volatile修饰的sizeCtl用于数组初始化与扩容控制
  private transient volatile int sizeCtl;
  ```

1. JDK1.8 取消了 segment 数组，**直接用 table 保存数据，锁的粒度更小**，减少并发冲突的概率。

2. JDK1.8 存储数据时采用了**链表+红黑树**的形式，纯链表的形式时间复杂度为O(n)，红黑树则为 O(logn)，性能提升很大。
  3. JDK1.8 的实现降低锁的粒度，JDK1.7版本锁的粒度是**基于Segment的，包含多个 HashEntry**，而JDK1.8锁的粒度**就是HashEntry（首节点）**
4. JDK1.8 版本的数据结构变得更加简单，使得操作也更加清晰流畅，**因为已经使用 synchronized 来进行同步**，所以不需要分段锁的概念，也就不需要 Segment 这种数据结构了，由于粒度的降低，实现的复杂度也增加了
  5. **JDK1.8 为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点**

        1. 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了

         2. JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然
         3. 在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存，虽然不是瓶颈，但是也是一个选择依据

> 扩展阅读：https://www.cnblogs.com/chengxiao/p/6842045.html
>

### LinkedHashMap 的实现原理

> 更多内容见博文：[Java：LinkedHashMap类小记](https://www.cnblogs.com/zhuchengchao/p/14447418.html)

LinkedHashMap 也是基于 HashMap 实现的，不同的是它定义了一个 **Entry head, tail**，这个 head, tail 不是放在 Table 里，它是额外独立出来的。

LinkedHashMap 中的静态内部类 Entry 类通过继承 hashMap 中的 Node，并添加两个属性 **Entry before，Entry after** 并结合 head，tail 组成一个双向链表，来实现按**插入顺序**或**访问顺序**排序。

```java
public class LinkedHashMap<K,V>
    extends HashMap<K,V>
    implements Map<K,V>
{
    // LinkedHashMap实现了静态内部类Entry，继承了HashMap.Node，
    // 同时定义了before, after两个属性
    static class Entry<K,V> extends HashMap.Node<K,V> {
        Entry<K,V> before, after;
        Entry(int hash, K key, V value, Node<K,V> next) {
            super(hash, key, value, next);
        }
    }
	// 链表的头结点，表示最老的那个节点
    transient LinkedHashMap.Entry<K,V> head;
	// 链表的尾节点，表示最新插入的那个节点
    transient LinkedHashMap.Entry<K,V> tail;
	// 链表的遍历顺序：
    final boolean accessOrder;
}
```

**因此，LinkedHashMap 其实就是可以看成 HashMap 的基础上，多了一个双向链表来维持顺序。**

其中，LinkedHashMap 定义了排序模式 accessOrder，该属性为 boolean 型变量，

* 对于**访问顺序**，为 true，按访问顺序排序，即每当访问一次元素，该元素就会被移动链表的最后面
* 对于**插入顺序**，则为 false，即按照插入元素的顺序进行排序；

一般情况下，不必指定排序模式，其迭代顺序即为默认为插入顺序。

> 推荐阅读：https://www.jianshu.com/p/8f4f58b4b8ab
>
> 参考：https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### TreeMap 实现原理

> 见：[Java：TreeMap类小记](https://www.cnblogs.com/zhuchengchao/p/14448137.html)

TreeMap 的实现就是**红黑树数据结构**，也就说是一棵自平衡的排序二叉树，这样就可以保证当需要快速检索指定节点；

TreeMap 中的每个 Entry 都被当成“红黑树”的一个节点对待；

```java
// 红黑树节点定义
static final class Entry<K,V> implements Map.Entry<K,V> {
    K key;
    V value;
    Entry<K,V> left;  // 当前节点的左子树
    Entry<K,V> right; // 当前节点的右子树
    Entry<K,V> parent;  // 当前节点的父节点
    boolean color = BLACK;  // 红/黑
    
    // ... 省略一下构造方法/get/set方法
	
    // 判断节点是否相等
    public boolean equals(Object o) {
        if (!(o instanceof Map.Entry))
            return false;
        Map.Entry<?,?> e = (Map.Entry<?,?>)o;

        return valEquals(key,e.getKey()) && valEquals(value,e.getValue());
    }
	
    // 计算Entry的hash值
    public int hashCode() {
        int keyHash = (key==null ? 0 : key.hashCode());
        int valueHash = (value==null ? 0 : value.hashCode());
        return keyHash ^ valueHash;
    }
}
```

> 参考：
>
> https://blog.csdn.net/jtcode_is_my_partner/article/details/81408392
>
> https://zhuanlan.zhihu.com/p/157315716

### Set & Set实现原理

**总结：**

- 首先，Set集合不包含重复元素，**都具有唯一性**；
- 当无排序要求可以选用 HashSet；
- 若想取出元素的顺序和放入元素的顺序相同，那么可以选用 LinkedHashSet；
- 若想插入、删除立即排序或者按照一定规则排序可以选用 TreeSet。

**Set接口的特性：**

Set 接口继承了 Collection 接口，Set 集合中不能包含重复的元素，每个元素必须是唯一的，你只要将元素加入 Set 中，重复的元素会自动移除。

常用的 Set 有：HashSet、LinkedHashSet 、TreeSet 

**HashSet特点：**

```java
public class HashSet<E>
    extends AbstractSet<E>
    implements Set<E>, Cloneable, java.io.Serializable{}
```

1. HashSet 中不能有相同的元素，但**可以有 null 元素**，即元素具有唯一性；

   且其底层采用的还是 HashMap，对于put元素，其采用的方式为：

   ```java
   // HashSet 的值都是存储在 HashMap 中的
   private transient HashMap<E,Object> map;
   public HashSet() {
       // HashSet 的构造法中会初始化一个HashMap对象，
       map = new HashMap<>();
   }
   public boolean add(E e) {
       // HashSet的值是作为HashMap的key存储在HashMap 中的
       return map.put(e, PRESENT)==null;  // 当存储的值已经存在时返回 false
       // private static final Object PRESENT = new Object();
   }
   ```

2. 存入 HashSet 的元素是无序的；

3. 添加、删除元素的操作时间复杂度都为 O(1)，因为其是基于HashMap进行的

   ```java
   public int size() {
       return map.size();
   }
   public boolean isEmpty() {
       return map.isEmpty();
   }
   public boolean add(E e) {
       return map.put(e, PRESENT)==null;
   }
   public boolean remove(Object o) {
       return map.remove(o)==PRESENT;
   }
   // ....
   ```

4. 非线程安全

**LinkedHashSet特点：**

1. 对于 LinkedHashSet 而言，它继承于 HashSet、又基于 LinkedHashMap 来实现的；

   ```java
   public class LinkedHashSet<E>
       extends HashSet<E>  // 继承了HashSet
       implements Set<E>, Cloneable, java.io.Serializable {
   
       public LinkedHashSet(int initialCapacity, float loadFactor) {
       	// 由于其继承自HashSet，因此调用的是HashSet的构造函数
       	// 而在HashSet构造函数中，有如下：△
           super(initialCapacity, loadFactor, true);
       }
   
   	public LinkedHashSet(int initialCapacity) {
           super(initialCapacity, .75f, true);
       }
   
   	public LinkedHashSet() {
           super(16, .75f, true);
       }
   }
   
   // 在HashSet类中△
   HashSet(int initialCapacity, float loadFactor, boolean dummy) {
   	// 创建了一个LinkedHashMap
   	map = new LinkedHashMap<>(initialCapacity, loadFactor);
   }
   ```

2. LinkedHashSet 中不能有相同元素，**可以有一个 null 元素**，元素严格按照放入的顺序排列（出于其基于LinkedHashMap实现，而LinkedHashMap维护了一个双向链表）；

3. 添加、删除元素的操作时间复杂度都为 O(1)；

4. 非线程安全。

**TreeSet特点：**

1. TreeSet 底层实际使用的存储容器就是 TreeMap；

   ```java
   public class TreeSet<E> extends AbstractSet<E>
       implements NavigableSet<E>, Cloneable, java.io.Serializable {
       
   	private transient NavigableMap<E,Object> m;
   
   	public TreeSet() {
   		// 底层实际使用的存储容器就是 TreeMap；
           this(new TreeMap<E,Object>());  // 调用 TreeSet
       }
       
       // 把TreeMap赋值给了NavigableMap<E,Object>
       TreeSet(NavigableMap<E,Object> m) {
           this.m = m;
       }
       
       public boolean add(E e) {
       	// 本质上还是调用了 TreeMap 的方法
           return m.put(e, PRESENT)==null;
       }
   }
   ```

2. TreeSet 中不能有相同元素，**不可以有null元素**，根据元素的自然顺序进行排序；

3. 添加、删除操作时间复杂度都是 O(log(n))；

4. 非线程安全

> 参考：https://blog.csdn.net/StemQ/article/details/66477615

### Set 保证元素不重复

```java
private transient HashMap<E,Object> map;   // HashSet的底层为一个HashMap结构
private static final Object PRESENT = new Object();  // 作为一个占位符
    
public boolean add(E e) { 
    return map.put(e, PRESENT)==null; 
}
```

元素值作为的是 map 的 key，map 的 value 则是 PRESENT 变量，这个变量只作为放入 map 时的一个占位符而存在，所以没什么实际用处。其实，这时候答案已经出来了：**HashMap 的 key 是不能重复的，而这里 HashSet 的元素又是作为了 map 的 key，当然也不能重复了。**

LinkedHashSet、TreeSet都一样，都采用了PRESENT这个占位符。

> 参考：https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### Collection 和 Collections 

**Collection：**是一个**集合接口**。它提供了对集合对象进行基本操作的通用接口方法。List，Set，Queue 接口都继承 Collection；直接实现该接口的类只有 AbstractCollection 类，该类也只是一个抽象类，提供了对集合类操作的一些基本实现。

**Collections：**是不属于 Java 的集合框架的，它是**集合类的一个工具类/帮助类**。此类不能被实例化， 服务于 Java 的 Collection 框架。它包含有关集合操作的静态多态方法，实现对各种集合的搜索、排序、线程安全等操作。

**常用功能**

- `public static <T> boolean addAll(Collection<T> c, T... elements)`：往集合中添加一些元素。
- `public static void reverse(List<?> list)`：将集合反转
- `public static void shuffle(List<?> list)` ：打乱顺序，打乱集合顺序。
- `public static <T> void sort(List<T> list) `：将集合中元素按照默认规则排序。
- `public static <T> void sort(List<T> list，Comparator<? super T> )` :将集合中元素按照指定规则排序。

> **Collections 中的 sort 方法**
>
> **Comparator 比较器**
>
> 排序方法：`public static <T> void sort(List<T> list)`：将集合中元素按照默认规则排序。
>
> 如，对字符串类型进行比较：
>
> ```java
> public class CollectionsDemo2 {
>        public static void main(String[] args) {
>            ArrayList<String> list = new ArrayList<String>();
>            list.add("cba"); list.add("aba"); list.add("sba"); list.add("nba");
>            //排序方法
>            Collections.sort(list);
>            System.out.println(list);
>        }
>    }
>    
>    // 结果：
> // [aba, cba, nba, sba]
> ```
> 
> 说到排序了，简单的说就是两个对象之间比较大小，那么在 Java 中提供了两种比较实现的方式，一种是比较死板的采用 `java.lang.Comparable` 接口去实现，一种是灵活的当我需要做排序的时候在去选择的`java.util.Comparator` 接口完成。
> 
>那么我们采用的 `public static <T> void sort(List<T> list)` 这个方法完成的排序，**实际上要求了被排序的类型需要实现 Comparable 接口完成比较的功能**，在 String 类型上如下：
> 
>```java
> public final class String implements java.io.Serializable, Comparable<String>, CharSequence {
>
>        // 实现了Comparable<String>的方法，该接口内有抽象方法public int compareTo(T o);
>        // 在String内对其进行了实现
>        public int compareTo(String anotherString) {
>            int len1 = value.length;
>            int len2 = anotherString.value.length;
>            int lim = Math.min(len1, len2);
>            char v1[] = value;
>            char v2[] = anotherString.value;
>    
>            int k = 0;
>            while (k < lim) {
>                char c1 = v1[k];
>                char c2 = v2[k];
>                if (c1 != c2) {
>                    return c1 - c2;
>                }
>                k++;
>            }
>            return len1 - len2;
>        }
>    }
>    ```
>    
> String 类实现了这个接口，并完成了比较规则的定义，但是这样就把这种规则写死了，那比如我想要字符串按照第一个字符降序排列，那么这样就要修改String的源代码，这是不可能的了。
> 
>```java
> // 重写排序的规则
>@Override
> public int compareTo(Person o) {
>        // return 0; // 认为元素都是相同的
>        // 自定义比较的规则, 比较两个人的年龄(this,参数Person)
>        // return this.getAge() - o.getAge();  // 年龄升序排序
>        return o.getAge() - this.getAge();  // 年龄降序排序
>    }
>    ```
>    
> 那么这个时候我们可以使用 `public static <T> void sort(List<T> list，Comparator<? super T> )` 方法灵活的完成，这个里面就涉及到了 **Comparator这个接口**，位于位于 `java.util` 包下，排序是 comparator 能实现的功能之一，该接口代表一个比较器，比较器具有可比性！顾名思义就是做排序的，通俗地讲需要比较两个对象谁排在前谁排在后，那么比较的方法就是：`public int compare(String o1, String o2)` ：比较其两个参数的顺序。
> 
>两个对象比较的结果有三种：大于，等于，小于。
> 
>如果要按照升序排序，则o1 小于o2，返回（负数），相等返回0，o1大于o2返回（正数）;
> 
>如果要按照降序排序，则o1 小于o2，返回（正数），相等返回0，o1大于o2返回（负数）
> 
>**总结 Comparator 的排序规则: o1-o2 为升序；o2-o1 为降序**
> 
>操作如下:
> 
>```java
> public class CollectionsDemo3 {
>        public static void main(String[] args) {
>            ArrayList<String> list = new ArrayList<String>();
>            list.add("cba");
>            list.add("aba");
>            list.add("sba");
>            list.add("nba");
>            // 自定义排序方法 按照第一个单词的降序
>            Collections.sort(list, new Comparator<String>() {
>                @Override
>                public int compare(String o1, String o2) {
>                    return o2.charAt(0) ‐ o1.charAt(0);
>                }
>            });
>            System.out.println(list);
>        }
>    }
>    
>    // 结果如下：
> // [sba, nba, cba, aba]
> ```
> 
> **总结：Comparable 与 Comparator 两个接口的区别**
> 
>**Comparable**：强行对实现它的每个类的对象进行整体排序。这种排序被称为类的自然排序，类的 compareTo 方法被称为它的自然比较方法。只能在类中实现 `compareTo()` 一次，不能经常修改类的代码实现自己想要的排序。实现此接口的对象列表（和数组）可以通过`Collections.sort`（和 `Arrays.sort`）进行自动排序，对象可以用作有序映射中的键或有序集合中的元素，无需指定比较器。
> 
>**Comparator**：强行对某个对象进行整体排序。可以将 Comparator 传递给 sort 方法（如`Collections.sort` 或 `Arrays.sort`），从而允许在排序顺序上实现精确控制。还可以使用 Comparator 来控制某些数据结构（如有序 set 或有序映射）的顺序，或者为那些没有自然顺序的对象 collection 提供排序。

> 参考：https://www.cnblogs.com/williamjie/p/11458701.html

### Iterator 的使用与其特点

迭代器是一种设计模式，它是一个对象，它可以遍历并选择序列中的对象，而开发人员不需要了解该序列的底层结构。迭代器通常被称为“轻量级”对象，因为创建它的代价小。

Java 中的 Iterator 功能比较简单，并且只能单向移动：　　

1. 使用方法 `public Iterator iterator()` 要求容器返回一个 Iterator。第一次调用 Iterator 的 `next()` 方法时，它返回序列的第一个元素。

   > 注意：`iterator()` 方法存在于 `java.lang.Iterable` 接口中，该接口被 Collection 继承，因此集合类可以使用方法`iterator()`返回一个迭代器
   >
   > ```java
   > // collection接口继承了Iterable接口
   > public interface Collection<E> extends Iterable<E> {}
   > 
   > // 被collection接口继承的Iterable接口中有方法iterator，其会返回一个Iterator对象
   > public interface Iterable<T> {
   >        Iterator<T> iterator();
   > }
   > 
   > // Iterator对象中相应的方法
   > public interface Iterator<E> {
   >        boolean hasNext();
   >        E next();
   >        default void remove() {
   >            throw new UnsupportedOperationException("remove");
   >        }
   > }
   > ```

2. 使用 `public E next()` 获得序列中的下一个元素。　

3. 使用 `public boolean hasNext()` 检查序列中是否还有元素。　　

4. 使用 `default void remove()` 将迭代器新返回的元素删除。

> 参考：https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### Iterator 和 ListIterator 的异同

**相同点：**

1. 都是迭代器，当需要对集合中元素进行遍历不需要干涉其遍历过程时，这两种迭代器都可以使用；

2. ListIterator 实现了 Iterator 接口；

   ```java
   public interface ListIterator<E> extends Iterator<E>
   ```

**不同点：**

1. **使用范围不同**：Iterator 可用来遍历 Set、List、Map集合，但是 **ListIterator 只能用来遍历 List**。
2. **遍历方向不同**：Iterator 对集合只能是前向遍历（`hasNext()`, `Next()`），ListIterator 既可以前向也可以后向(`hasNext()`, `Next()`, `hasPrevious()`, `previous()`)；
3. ListIterator 可以定位当前索引的位置，`nextIndex()`和`previousIndex()`可以实现。Iterator没有此功能。
4. ListIterator有add方法，可以向List中添加对象，而Iterator不能；
5. 都可实现删除操作，但是 ListIterator 可以实现对象的修改，`set()`方法可以实现。Iterator仅能遍历，不能修改

**总之**：ListIterator 实现了 Iterator 接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引等等。

> 参考：https://blog.csdn.net/xiangyuenacha/article/details/84253630

### Iterator 和 Enumeration 的区别

与 Enumeration 相比，Iterator 更加安全，因为当一个集合正在被遍历的时候，它会阻止其它线程去修改集合。否则会抛出 ConcurrentModificationException 异常。这其实就是 fail-fast 机制。具体区别有三点：

1. Iterator 的方法名比 Enumeration 更科学；
2. **Iterator 有 fail-fast 机制，比 Enumeration 更安全**；
3. Iterator 能够删除元素，Enumeration 并不能删除元素。

函数接口如下：

```java
package java.util;

public interface Enumeration<E> {
    boolean hasMoreElements();
    E nextElement();
}

public interface Iterator<E> {
    boolean hasNext();
    E next();
    void remove();
}
```

> 参考：https://mp.weixin.qq.com/s/q1r9Pno6ANUzZ9wMzA-JSg

### fail-fast 与 fail-safe 的区别 :exclamation:

**fail-fast：**

fail-fast 的字面意思是“快速失败”。当我们在遍历集合元素的时候，经常会使用迭代器，但在迭代器遍历元素的过程中，如果集合的结构被改变的话，就会抛出异常，防止继续遍历。这就是所谓的快速失败机制。

**fail-fast 迭代器抛出 ConcurrentModificationException，而 fail-safe 迭代器则不会**。

> 结构上的改变：集合上的插入和删除就是结构上的改变；
>
> 对集合中某个元素进行修改的话，并不是结构上的改变；
>
> 抛出 ConcurrentModificationException 异常实例：
>
> ```java
> @Test
> public void testFailFast(){
>        List<Integer> list = new ArrayList<>();
>        for(int i = 0; i < 20; i++){
>            list.add(i);
>        }
>        Iterator<Integer> it = list.iterator();
>        int temp = 0;
>        while(it.hasNext()){
>            if(temp == 3){
>                temp++;
>                list.remove(3);  // 在迭代的过程中，改变了集合的结构，导致fail-fast
>            }else{
>                temp++;
>                System.out.println(it.next());
>            }
>        }
> }
> ```

**fail-fast 工作原理：**

```java
// 取下一个元素时
public E next() {
	checkForComodification();
    ...
}

final void checkForComodification() {
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
}
```

当迭代器在执行 `next()` 方法时，会调用`checkForComodification()`，当`modCount != expectedModCount`时则抛出异常，而当集合的结构发生变化时，modCount就会发生改变，如

```java
// ArrayList 在添加元素时，modCount 就会被改变
public boolean add(E e) {
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    elementData[size++] = e;
    return true;
}

private void ensureCapacityInternal(int minCapacity) {
    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
}

private void ensureExplicitCapacity(int minCapacity) {
    modCount++;  // 这里修改了！！！

    // overflow-conscious code
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}
```

**fail-fast 的一些处理方法：**

如果我们不希望在迭代器遍历的时候因为并发等原因，导致集合的结构被改变，进而可能抛出异常的话，我们可以在涉及到会影响到 modCount 值改变的地方，加上同步锁 synchronized，或者直接使用 `Collections.synchronizedList` 来解决。

**fail-safe：**

java.util 包中的所有集合类都被设计为 fail-fast 的，而 **java.util.concurrent 中的集合类都为 fail-safe 的**。

对于采用 fail-safe 机制来说，当检测到正在遍历的集合的结构被改变时，不会抛出异常；

这是因为，**当集合的结构被改变的时候，fail-safe 机制会复制原集合的一份数据出来，然后在复制的那份数据上继续遍历。**

> 然后在添加的时候，会复制一份副本出来添加元素，然后再新的设置回去....
>
> 就是写的时候，把容器扩容一个出来，然后把值填写上去，再通知其他的线程，把原先容器的引用指向扩容后的容器。

因此，虽然fail-safe不会抛出异常，但存在以下缺点：

1. 复制时需要额外的空间和时间上的开销。
2. 不能保证遍历的是最新内容。

> 参考：https://www.jianshu.com/p/bee159e0bd49

