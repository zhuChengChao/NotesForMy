# 面经：11-中间件

> 个人整理 :muscle: 个人专用 :muscle: 暑期实习 :muscle: 秋招 :muscle: 后端开发 :muscle: 八股文 :no_mouth:

## ELK

### 使用 ES 的原因

问题：系统中的数据，随着业务的发展，时间的推移，将会非常多，而业务中往往采用模糊查询进行数据的搜索，而**模糊查询会导致查询引擎放弃索引**，导致系统查询数据时都是全表扫描，在百万级别的数据库中，查询效率是非常低下的。

而使用 ES 做一个**全文索引**，将经常查询的系统功能的某些字段，比如说电商系统的商品表中商品名，描述、价格还有 id 这些字段我们放入 ES 索引库里，可以提高查询速度。

### 倒排索引 :exclamation:

倒排索引是搜索引擎的核心。

**搜索的概念**：用户输入想要的关键词，返回含有该关键词的所有信息。而传统的检索方式是根据关键词，逐个遍历所有的记录，然后返回含有关键词的记录。

**倒排索引**：源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引。

**全文检索**：

- **这种先建立索引，再对索引进行搜索的过程就叫全文检索(Full-text Search)  ，其中的索引就是倒排索引**
- 将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。
- 这部分从非结构化数据中提取出的然后重新组织的信息，我们称之索引。

> 例如： 字典。 字典的拼音表和部首检字表就相当于字典的索引，对每一个字的解释是非结构化的，如果字典没有音节表和部首检字表，在茫茫辞海中找一个字只能顺序扫描。然而字的某些信息可以提取出来进行结构化处理，比如读音，就比较结构化，分声母和韵母，分别只有几种可以一一列举，于是将读音拿出来按一定的顺序排列，每一项读音都指向此字的详细解释的页数。我们搜索时按结构化的拼音搜到读音，然后按其指向的页数，便可找到我们的非结构化数据，即对字的解释。  

### ES：核心概念

**集群**：包含一个或多个启动着 ES 实例的机器群，通常一台机器起一个 ES 实例，同一网络下，集名一样的多个 ES 实例自动组成集群，自动均衡分片等行为，默认集群名为 “elasticsearch”；

**节点**：节点是属于集群一部分的单个服务器，它存储数据并参与群集索引和搜索功能。

- **主结点**：master 节点主要用于集群的管理及索引 比如新增结点、分片分配、索引的新增和删除等。
- **数据结点**：data 节点上保存了数据分片，它负责索引和搜索操作。 
- **客户端结点**：client 节点仅作为请求客户端存在，client 的作用也作为负载均衡器，client 节点不存数据，只是将请求均衡转发到其它结点。

**index 索引**：包含一堆有相似结构的文档数据，就像关系数据库中的“数据库”。索引是逻辑名称空间，映射到一
个或多个主分片，并且可以有零个或多个副本分片。

**Document 文档**：ES 中的最小数据单元，一个 document 就像数据库中的一条记录，通常以 Json 格式显示，多个 document 存储于一个索引（Index）中。

**Field 字段**：就像数据库中的列（Columns），定义每个 document 应该有的字段。

**Type 类型：**每个索引里都可以有一个或多个 type，type 是 index 中的一个逻辑数据分类，一个 type 下的 document，都有相同的 field。

> **注意**：6.0 之前的版本有 type（类型）概念，type 相当于关系数据库的表，ES 官方将在 ES9.0 版本中彻底删除 type。

**shard 分片：**index 数据过大时，将 index 里面的数据，分为多个 shard，分布式的存储在各个服务器上面。可以支持海量数据和高并发，提升性能和吞吐量，充分利用多台机器的 cpu。

**replica：副本**

- 在分布式环境下，任何一台机器都会随时宕机，如果宕机，index 的一个分片没有，导致此 index 不能搜索。所以，为了保证数据的安全，我们会将每个 index 的分片经行备份，存储在另外的机器上。保证少数机器宕机es集群仍可以搜索。
- 能正常提供查询和插入的分片我们叫做主分片（primary shard），其余的我们就管他们叫做备份的分片（replica shard）。

> ES 6 默认新建索引时，5分片，2副本，也就是一主一备，共10个分片；而在 ES 7，默认分片数为1，副本也为 1

### ES 的 master 相关

**配置**

```yaml
# 指定该节点是否有资格被选举成为master结点，默认是true，如果原来的master宕机会重新选举新的master。
node.master: true
# 可以作为主节点的节点列表
cluster.initial_master_nodes: ["node-1"]  
# 主结点数量的最少值,此值的公式为：(master_eligible_nodes / 2) + 1 ，比如：有3个符合要求的主结点，那么这里要设置为2。
discovery.zen.minimum_master_nodes:
```

**Master 选举流程**

- Elasticsearch 的选主是 ZenDiscovery 模块负责的；
- 对所有可以成为 Master 的节点（node.master: true）根据 nodeId 字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第 0 位）节点，暂且认为它是 Master 节点；  
- 如果对某个节点的投票数达到一定的值（可以成为 master 节点数 n/2+1）并且该节点自己也选举自己，那这个节点就是 Master，否则重新选举一直到满足上述条件；
- Master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理。

**什么时候触发**：

1. 集群启动；
2. Master 失效；

**脑裂问题**

- “脑裂”问题可能的成因：

  **网络问题**：集群间的网络延迟导致一些节点访问不到 master，认为 master 挂掉了从而选举出新的 master，并对 master 上的分片和副本标红，分配新的主分片；

  **节点负载**：主节点的角色既为 master 又为 data，访问量较大时可能会导致 ES 停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。

  **内存回收**：data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应。  

- 脑裂问题解决方案：

  **减少误判**：`discovery.zen.ping_timeout` 节点状态的响应时间，默认为 3s，可以适当调大，如果 master 在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如 6s，`discovery.zen.ping_timeout=6`），可适当减少误判。

  **选举触发**：`discovery.zen.minimum_master_nodes=1`，该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值，且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为 `(n/2) +1`， n 为主节点个数（即有资格成为主节点的节点个数） 

  **角色分离**：即 master 节点与 data 节点分离，限制角色

  - 主节点配置为： `node.master: true`，`node.data: false`
  - 从节点配置为：`node.master: false`，`node.data: true`  

### ES 索引-Index :exclamation:

**图解：**

![段和提交点](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251815602.PNG)

**索引不可变**：

- ES 的索引，在落盘之后是不可变，即不可对其进行二次修改，如果想要修改，必须先删除后重建。
- 不变性有重要的价值：
  - **不需要锁**，假如索引可变，就必须增加锁的机制。
  - **更高效利用缓存**：由于索引不可变，当索引一旦被读入内存，它就可以在一直在那儿。只要系统有足够的内存空间，大量的读就可以直接通过访问内存来完成，极大提高系统的性能。
- 存在问题：不能修改它，即每增加新文档的时候，都需要把旧索引全部删除，再重建。
- 解决方案：动态索引，见下方。

**动态索引**：

- 动态索引的本质就是**多个索引**，即新增文档时，直接生成一个新的索引，查询时，**把每个索引的数据都查出来后，再进行聚合处理**。这种方式，既保留了索引不可变的优势，又解决了更新的问题。
- 但是，这种动态索引又产生了一个新的问题，**即当新建的索引越来越多时，会影响到聚合的效率**，也就会影响到查询的效率。
- 解决方案1：对于这种情况，我们可能会**从业务角度来处理**。即选择非热点时段，进行索引的重建和切换。
- 解决方案2：**es 也为这种情况准备了 segment 合并的策略**。

**segment**：

- 文档经过 ES 处理后，会形成倒排索引，放到 ES 的某个或某几个分片上；
- 所以，ES 的每个分片上，往往会包含很多个倒排索引，**我们把每一个倒排索引，称之为 segment**，即每一个 segment 都是一个倒排索引；
- 在查询的时候，ES 会把所有的 segment 的查询结果**合并汇总成最后的结果再返回**。
- **索引不可变，事实上就是 segment 不可变**；
- 当 segment 不断增多时，合并汇总的压力会增大，此时，**ES 会触发 segment 合并的线程，把许多小的segment 合并成一个大的 segment，并删除原来的小的 segment**。

**近实时化搜索**：

- 近实时化搜索的含义指的是当写入一个文档后，该文档在很短时间内就可以被通过关键词搜索到。
- 前面提到，ES 之所以能达到近实时化搜索的关键是，**只要缓存区的内容在 filesystem cache 中形成segment （1s，reflush，生成新的段） 后，它就能被搜索了**。
- 对于于早期的 lucene，只有当 segment 被写入磁盘才能被搜索，简直不要进步的太多。对比会发现，这中间，从开始创建到能被搜索，事实上省掉了磁盘IO。

**commit point**

- 直译为提交点，**ES 用它来记录当前所有可用 segment**，以及被删除的 segment（标记删除）；

- commit point 在 segment 合并阶段，起到帮助合并且维持搜索的作用。每次合并都会通过记录 commit point 的方式，告诉前来的查询，哪些段是可用的，哪些段是已经被删除的。

- **合并过程**大致如下：

  1. 选择一些大小相似的 segment 合并成一个较大的 segment；

     > 为了保证近实时，每 1s 进行 reflush 都会产生一个新的段供搜索，但不落盘

  2. 将新的 segment **刷到磁盘上**。

  3. 创建新的 commit point，其中，记录了新的 segment，并删除的旧的。

  4. 将新的 segment 打开供搜索。

**translog**：

- 类似于 MySQL 通过重做日志 redo 来实现事务的持久化；
- 对于 ES 来说，**文档也不是直接就放进文件中，而是先会在内存中进行处理，处理成索引信息后，会等到缓冲区满或显式提交时，才会保存到文件中**；
- 在保存之前 ES 进程挂掉，如果没有其它机制，就肯定会丢数据；
- translog 来了。即在数据进行索引前，会**先写 translog 日志**，该日志是写在文件中的。当 ES 进程出现问题，需要恢复数据时，就会基于 translog 进行重放日志。这样，就保证了数据的不丢失。
- 默认：translog 每隔 5 秒会被写入磁盘，或者在每次写请求完成之后执行，可以配置为异步的。

### 索引的过程

> 在分析了 index 的概念后，后对索引过程做进一步了解了

![索引过程](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251815577.PNG)

基于上图，我们可以完整整理出一个 ES 对文档进行索引的基本过程，如下：

1. 接收到客户端传过来的文档后，会首先写入 translog 日志和内存缓冲区 buffer；

   > 其中的 translog 为了保证消息的可靠性，当 filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush； 

2. 每隔一秒，缓冲区中的内容会被刷新到 filesystem cache 中，成为一个新的 segment。此时，该 segment 就会被打开，**可以进行搜索了**；

   > 这也是es能实现近实时性被搜索的关键，一次 **reflush**

3. 每秒都有 segment 刷入，segment 数量不断增长，就会触发合并，即将小的 segment 合并成大的，这个就是 flush 过程；

4. 最后把合并成的大的 segment 写入到磁盘上，生成新的 commit point，就完成了整个文档的索引过程，同时会清空 translog

四个阶段可以整理成四个关键词：**translog/cache -> segment -> 合并 -> 写入**

### ES 查询文档流程

1. 客户端发送请求到任意一个 node，成为协调节点（coordinate node）

2. coordinate node 对 document 进行路由，将请求转发到对应的 node，此时会使用 **round-robin 随机轮询算法**，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡

   > 数据路由算法：`shard = hash(document_id) % (num_of_primary_shards)` 

3. 接收请求的 node 返回 document 给 coordinate node

4. coordinate node 返回 document 给客户端

> **特殊情况**：document 如果还在建立索引过程中，可能只有 primary shard 有，任何一个 replica shard 都没有，此时可能会导致无法读取到 document，但是 document 完成索引建立之后，primary shard 和 replica shard 就都有了。

图示：

![读一个文档](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251815738.png)

**进一步**：当存在**评分问题**时，搜索被执行成一个两阶段过程，我们称之为 **Query Then Fetch**； 

> 会存在一个 Deep Paging 问题

- 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。每个分片在本地执行搜索并**构建一个匹配文档的大小为 from + size 的优先队列**。

  > PS：在搜索的时候是会查询 Filesystem Cache 的，但是有部分数据还在 Memory Buffer，所以搜索是近实时的。 

- 每个分片返回各自优先队列中**所有文档的 ID 和排序值**给协调节点，它**合并这些值到自己的优先队列**中来产生一个全局排序后的结果列表。

- 接下来就是**取回阶段**，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。 

### ES 增删改文档

增删改可以看做 update，都是对数据的改动。一个改动请求发送到 es 集群，经历以下四个步骤：

1. 客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node（协调节点）
2. coordinating node，对 document 进行路由，将请求转发给对应的 node（有primary shard）
3. 实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node。
4. coordinating node，如果发现 primary node 和所有 replica node 都搞定之后，就返回响应结果给客户端。

图示：

![文档操作](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251815415.png)

进一步：

- ES 中的文档是不可变的，因此不是进行真正的删除，该文档依然能匹配查询，但是**会在结果中被过滤掉**
- 磁盘上的每个段都有一个相应的 `.del` 文件，删除后会在 `.del` 文件中被标记为删除，当段合并时，在 `.del` 文件中被标记为删除的文档将不会被写入新段。 
- 新建文档时，ES 会为该文档指定一个**版本号**，当执行更新时，旧版本的文档在 `.del` 文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是**会在结果中被过滤掉**。 

### ES 读写一致性 / 并发控制

**并发问题**：在多线程情况下，es 同样会出现并发冲突问题，即多个用户同时更新 ES 文档；

**乐观并发控制**：

- 为控制并发问题，我们通常采用锁机制。分为悲观锁和乐观锁两种机制。

- **悲观锁**：很悲观，所有情况都上锁。此时只有一个线程可以操作数据。具体例子为数据库中的行级锁、表级锁、读锁、写锁等。

  特点：优点是方便，直接加锁，对程序透明。缺点是效率低。

- **乐观锁**：很乐观，对数据本身不加锁。提交数据时，通过一种机制验证是否存在冲突，如 **es 中通过版本号验证**。

  特点：优点是并发能力高。缺点是操作繁琐，在提交数据时，可能反复重试多次。

- ES 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。 ES 也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许顺序是乱的 。**ES 需要一种方法确保文档的旧版本不会覆盖新的版本** 

  ES 利用了 version 号来确保应用中相互冲突的变更不会导致数据丢失

  > 老的版本 ES 使用 version，但是新版本不支持了，提示我们用 `if_seq_no` 和 `if_primary_term`
  >
  > - 不支持：`PUT /test_index/_doc/3?version=1`
  > - 目前支持：`PUT /test_index/_doc/3?if_seq_no=12&if_primary_term=1`

- **外部系统版本控制**：已有数据是在数据库中，有自己手动维护的版本号的情况下，可以使用 external version 控制。

  要求：修改时 external version 要**大于**当前文档的 _version，而内部版本号比较方式是 **等于**；

  使用：`?version=1&version_type=external`

**其他**：

- 另外对于写操作，一致性级别支持 `quorum/one/all`，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
- 对于读操作，可以设置 replication 为 sync (默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数 _preference 为 primary 来查询主分片，确保文档是最新版本。

### ES 分析 analyzer

分析包含下面的过程：

1. 将一块文本分成适合于倒排索引的独立的**词条 term**

2. 将这些词条统一化为标准格式以提高它们的”可搜索性”，或者 recall，召回率；

   > recall，召回率：搜索的时候，增加能够搜索到的结果的数量

分析器执行上面的工作。分析器实际上是将三个功能封装到了一个包里：

1. **字符过滤器**：字符串按顺序通过每个字符过滤器，他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉 HTML，或者将 & 转化成 and；
2. **分词器**：字符串被分词器分为单个的词条，有 standard analyzer 标准分词器 / simple analyzer简单分词器 / language analyzer 特定的语言的分词器（IK 分词器）
3. **Token 过滤器**：词条按顺序通过每个 token 过滤器，大小写转换/去掉停用词/单词变成词干/同义词转换

### ES 字典树

字典树又称单词查找树，Trie 树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：**利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较**，查询效率比哈希树高。

Trie 的核心思想是**空间换时间**，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。

它有 3 个基本性质:

- 根节点不包含字符，除根节点外每一个节点都只包含一个字符。
- 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。
- 每个节点的所有子节点包含的字符都不相同。

对于中文的字典树，**每个节点的子节点用一个哈希表存储**，这样就不用浪费太大的空间，而且查询速度上可以保留哈希的复杂度 O(1)。

> 因为英文只有26个字母，无需采用 hash 表，直接用数组即可；而中文字比较多...

### Logstash

概述：

- Logstash 是一个数据抽取工具，将数据从一个地方转移到另一个地方；
- Logstash 配置文件有如下三部分组成，其中 **input**、**output** 部分是必须配置，**filter** 部分是可选配置，而 filter 就是过滤器插件，可以在这部分实现各种日志过滤功能。

**配置文件**：/config/xxx.conf

```bash
input {
    # 输入插件
}
filter {
    # 过滤匹配插件
}
output {
    # 输出插件
}
```

**输入插件**：标准输入 stdin / 读取文件 file / 读取 TCP 网络数据；

**过滤器插件**：

- Grok 正则捕获：通过**正则解析任意文本**，将非结构化日志数据弄成结构化和方便查询的结构。**Grok 的语法规则是**：`%{语法: 语义}`
- date 插件，用来**转换日志记录中的时间字段**
- 数据修改 Mutate

**输出插件**：

- file：表示将日志数据写入磁盘上的文件；
- elasticsearch：表示将日志数据发送给 Elasticsearch。

## RabbitMQ

### 消息队列概述 :exclamation:

MQ（message queue），从字面意思上看，**本质是个队列，FIFO 先入先出**，只不过队列中存放的内容是  message 而已，**这是一种跨进程的通信机制**，用于上下游传递消息。

**消息队列是典型的：生产者、消费者模型**。生产者不断向消息队列中生产消息，消费者不断的从队列中获取消息。因为消息的生产和消费都可以是异步的，而且只关心消息的发送和接收，没有业务逻辑的侵入，这样就实现了**生产者和消费者的解耦**。

**使用 MQ 的原因：**

- **流量消峰**  

> 举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。  

- **应用解耦**

> 以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内容被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。

- **异步处理**  

> 有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完，以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题，A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ， MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样B 服务也不用做这些操作。 A 服务还能及时的得到异步处理成功的消息。  

**缺点**：

- MQ 存在挂掉的可能（集群可以解决）；
- 系统复杂度提高，需要考虑消息的幂等性，避免重复消费的情况；
- 一致性问题，部分消息成功，部分失败，导致数据不一致。

### AMQP 高级消息队列协议

MQ 是消息通信的模型，并不是具体实现。现在实现 MQ 的有两种主流方式：AMQP、JMS（Java Message Service）。

> 两者间的区别和联系：
>
> - JMS是定义了统一的接口，来对消息操作进行统一；AMQP是通过规定协议来统一数据交互的格式
> - JMS限定了必须使用Java语言；**AMQP只是协议，不规定实现方式，因此是跨语言的**。
> - JMS规定了两种消息模型；而AMQP的消息模型更加丰富

**RabbitMQ 就是 AMQP 协议的 Erlang 的实现**，AMQP 的模型架构和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。

RabbitMQ 中的交换器、交换器类型、队列、绑定、路由key 等都是遵循的 AMQP 协议中相应的概念。

> AMQP 三层
>
> - Module Layer：协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。
> - Session Layer：中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。
> - TransportLayer：最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。

### RabbitMQ 概述 :exclamation:

RabbitMQ 是一款开源的，Erlang 编写的，基于 AMQP（高级消息队列协议） 协议的，消息中间件；

**优点**

- **可靠性**：RabbitMQ 使用一些机制来保证可靠性，如持久化（消息/队列）、发布确认等；
- **灵活的路由**：在消息进入队列之前，通过交换器来路由消息。
- **高可用性**：队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。
- **多语言客户端**：RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。
- **管理界面**：RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集群中的节点等。
- **插件机制**：RabbitMQ 提供了许多插件，以实现从多方面进行扩展，当然也可以编写自己的插件

**四大组件**

1. **生产者**：产生数据发送消息的程序是生产者
2. **交换机**：交换机是 RabbitMQ 非常重要的一个部件，**一方面它接收来自生产者的消息，另一方面它将消息推送到队列中**。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得由**交换机类型**决定。
3. **队列**：队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式
4. **消费者**：消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。

### RabbitMQ 工作原理

![工作原理](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251815897.PNG)

- **Broker**：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker，一般一个 Broker 就是一个 RabbitMQ 的服务器；
- **Exchange**： message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：direct (point-to-point)，topic (publish-subscribe) ，fanout (multicast)
- **Queue**： 消息最终被送到这里等待 consumer 取走
- **Binding**：exchange 和 queue 之间的虚拟连接， binding 中可以包含 routing key， Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据  
- **Connection**：publisher／consumer 和 broker 之间的 TCP 连接
- **Channel**：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。**Channel 是在 Connection 内部建立的逻辑连接**，如果应用程序支持多线程，通常每个 thread 创建单独的 Channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 Channel 之间是完全隔离的。 **Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销**。
- **Virtual host**：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等

### RoutingKey & Binding

**RoutingKey**：

生产者将消息发送给交换器的时候，会指定一个 `RoutingKey`，用来指定这个消息的路由规则，这个 `RoutingKey` 需要与交换器类型和绑定键（`BindingKey`）联合使用才能最终生效。

**Binding：**

通过绑定将交换器和队列关联起来，一般会指定一个 `BindingKey`，这样 RabbitMQ 就知道如何正确路由消息到队列了，即：**队列只对它绑定的交换机的消息感兴趣**，而绑定的参数就是 `BingdingKey`

### 交换器4种类型 :exclamation:

**交换机概念**：

RabbitMQ 消息传递模型的核心思想是，**生产者生产的消息从不会直接发送到队列**。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。

相反，**生产者只能将消息发送到交换机（exchange）**，交换机工作的内容非常简单，一方面它接收来自生产者的消息，另一方面将它们推入队列。**交换机必须确切知道如何处理收到的消息。是应该把这些消息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。**这就是由交换机的类型来决定。  

总共有以下类型：

- **直接(direct)：**消息只去到与交换机绑定的队列中去，通过 BingdingKey
- **主题(topic)：**可以让队列在绑定 `Routing key` 的时候使用通配符：
  - `#`：匹配一个或多个词，如：`audit.#`：能够匹配`audit.irs.corporate` 或者 `audit.irs`
  - `*`：匹配不多不少恰好1个词，如：`audit.*`：只能匹配`audit.irs`
- **标题(headers)：**不依赖路由键匹配规则路由消息。是根据发送消息内容中的 `headers` 属性进行匹配，性能差，基本用不到。
- **扇出(fanout)**：它是将接收到的所有消息广播到它知道的所有队列中。

### 五种消息模型 :exclamation:

![五种消息模型](https://xycnotes.oss-cn-hangzhou.aliyuncs.com/img/202206251815015.png)

**第一种：基本消息模型**

- 官方文档介绍：RabbitMQ 是一个消息代理：它接受和转发消息。 你可以把它想象成一个邮局：当你把邮件放在邮箱里时，你可以确定邮差先生最终会把邮件发送给你的收件人。 在这个比喻中，RabbitMQ 是邮政信箱，邮局和邮递员。

  RabbitMQ 与邮局的主要区别是它不处理纸张，而是接受，存储和转发数据消息的二进制数据块。

- 总之：**生产者将消息发送到队列，消费者从队列中获取消息，队列是存储消息的缓冲区。**

**第二种：工作队列**

- 工作队列，又称任务队列。
- 主要思想就是避免执行资源密集型任务时，必须等待它执行完成。相反我们稍后完成任务，我们将任务封装为消息并将其发送到队列。 
- 在后台运行的工作进程将获取任务并最终执行作业。当你运行许多消费者时，任务将在他们之间共享，但是**一个消息只能被一个消费者获取**。

> 避免消息堆积？
>
> 1. 采用 WorkQueue，多个消费者监听同一队列；
>    1. WorkQueue 默认情况下，消息是轮训分发的；
>    2. 通过设置：`channel.basicQos(1);`可以实现消息的不公平分发；
>    3. 进一步，上述 `channel.basicQos(x);` 设置了队列的预取值，即定义通道上允许的未确认消息的最大数量
> 2. 接收到消息以后，而是通过线程池，异步消费；

**后面几种：**

- 3、4、5 这三种都属于订阅模型，**只不过进行路由的方式不同**。
- 工作队列背后的假设是：每个任务只被传递给一个工作人员。 
- **订阅模型中：我们将会传递一个信息给多个消费者。 这种模式被称为“发布/订阅”。** 

### 一次完整的生产消费

**生产者**

1. `Producer`先连接到 Broker，建立连接 Connection，开启一个信道 Channel
2. `Producer`声明一个交换器 exchange 并设置好相关属性
3. `Producer`声明一个队列 queue 并设置好相关属性
4. `Producer`通过路由键 routing key 将交换器和队列绑定 binding 起来
5. `Producer`发送消息到`Broker`，其中包含路由键、交换器等信息
6. 相应的交换器根据接收到的路由键查找匹配的队列
7. 如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者
8. 关闭信道
9. 关闭连接

**消费者**

1. `Producer`先连接到`Broker`，建立连接`Connection`，开启一个信道`Channel`
2. 向`Broker`请求消费响应的队列中消息，可能会设置响应的回调函数
3. 等待`Broker`回应并投递相应队列中的消息，接收消息
4. 消费者确认收到的消息，`ack`
5. `RabbitMq`从队列中删除已经确定的消息
6. 关闭信道
7. 关闭连接

### 如何保证消息的可靠性 :exclamation:

不可靠的地方：消息到 MQ 的过程中搞丢，MQ自己搞丢，MQ到消费过程中搞丢。

**消息到 MQ 的过程中搞丢解决方案：**

- **事物**：

  - 发送消息前，开启事务（`channel.txSelect()`），然后发送消息，如果发送过程中出现什么异常，事务就会回滚（`channel.txRollback()`），如果发送成功则提交事务（`channel.txCommit()`）。然而，这种方式有个缺点：吞吐量下降；
  - 事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。

- **发布确认**：

  - 生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式， 所有在该信道上面发布的消息都将会被指派一个唯一的 ID（从 1 开始）；

    > SpringBoot 中的配置：spring.rabbitmq.publisher-confirm-type=correlated

  - 一旦消息被投递到所有匹配的队列之后， broker 就会发送一个确认给生产者（包含消息的唯一 ID），这就使得生产者知道消息已经正确到达目的队列了；

  > - 如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出；
  > - broker 回传给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置 basic.ack 的 multiple 域，表示到这个序列号之前的所有消息都已经得到了处理。

  - confirm 模式最大的好处在于他是**异步的**，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息，生产者应用程序同样可以在回调方法中处理该 nack 消息。  

- **回退消息**：

  - 在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，**如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的**
  - 通过设置 mandatory 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者：`spring.rabbitmq.template.mandatory=true`

- **备份交换机**：备份交换机可以理解为 RabbitMQ 中交换机的“备胎” ，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，**当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中**，由备份交换机来进行转发和处理。

**MQ自己搞丢解决方案：**

- **持久化**：将队列和消息都标记为持久化；

  > 尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在当消息刚准备存储在磁盘的时候，但是还没有存储完，消息还在缓存的一个**间隔点**。此时并没有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。

- **搭建集群**：普通集群模式、镜像集群模式（高可用模式）

- **镜像队列**：引入镜像队列（Mirror Queue）的机制，可以将队列镜像到集群中的其他 Broker 节点之上，如果集群中的一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性。

**MQ 到消费过程中搞丢解决方案：**

- **消息应答**：消费者在接收到消息并且处理该消息之后，告诉 RabbitMQ 它已经处理了，RabbitMQ 可以把该消息删除了；分为：自动应答、手动应答
- **消息补偿机制：消息自动重新入队**：如果消费者由于某些原因失去连接（其通道已关闭，连接已关闭或 TCP 连接丢失），导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。
- **死信队列**：见后续分析

### 消息幂等性 :exclamation:

**幂等概念**：用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。

**MQ 中重复消费**：消费者在消费 MQ 中的消息时， MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断，故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。

**解决思路**：

1. **唯一ID+指纹码机制，利用数据库主键去重；**
2. **利用 redis 的原子性去实现**：利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费。

### 死信队列

**概念**：

死信，顾名思义就是无法被消费的消息；一般来说， producer 将消息投递到 broker 或者直接到 queue 里， consumer 从 queue 取出消息进行消费，但某些时候由于特定的原因**导致 queue 中的某些消息无法被消费**，这样的消息如果没有后续的处理，就变成了死信，有死信自然就有了死信队列。

**导致的死信的几种原因**

1. 消息 TTL 过期
2. 队列达到最大长度（队列满了，无法再添加数据到 MQ 中）
3. 消息被拒绝（basic.reject 或 basic.nack）并且 requeue=false，即不重新放入队列

### 延迟队列

**概念**：

存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。

**TTL（Time TO Live）**：

**TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间**，单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者消息进入了设置了 TTL 属性的队列，**那么这条消息如果在 TTL 设置的时间内没有被消费，则会成为"死信"**。如果同时配置了队列的 TTL 和消息的 TTL，那么较小的那个值将会被使用。

**有两种方式设置 TTL**：

- 消息设置 TTL

- 队列设置 TTL

- 两者的区别：

  如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃（如果配置了死信队列被丢到死信队列中）；

  设置了消息的 TTL，消息即使过期，也不一定会被马上丢弃，因为**消息是否过期是在即将投递到消费者之前判定的**

### 优先队列

使得消息具有优先级，要让队列实现优先级需要做如下事情；

1. 队列需要设置为优先级队列，参数：x-max-priority
2. 消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息进行排序；

> 即：当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义

### 事务机制

RabbitMQ 客户端中与事务机制相关的方法有三个：

- `channel.txSelect` 用于将当前的信道设置成事务模式。
- `channel.txCommit` 用于提交事务。
- `channel.txRollback` 用于事务回滚，如果在事务提交执行之前由于 RabbitMQ 异常崩溃或者其他原因抛出异常，通过 `channel.txRollback` 来回滚。

## CAT(待完善:stuck_out_tongue_winking_eye:)

### 调用链监控

首先，开始微服务架构之后，**服务变成分布式**的了，对服务进行了拆分。当用户的一个请求进来，会依次经过不同的服务节点进行处理，处理完成后再返回结果给用户。那么在整个处理的链条中，如果有任何一个节点出现了延迟或者问题，都有可能导致最终的结果出现异常，有的时候不同的服务节点甚至是由不同的团队开发的、部署在不同的服务器上，那么在这么错综复杂的环境下，我们想要排查出是链条中的具体哪个服务节点出了问题，其实并不容易。

因而提出了**调用链监控**，除了能帮助我们定位问题以外，还能帮助项目成员清晰的去了解项目部署结构。

有这些需求：

1. 线上的服务是否运行正常。是不是有一些服务已经宕机了，但是我们没有发现呢？如何快速发现已经宕机的服务？
2. 来自用户的一笔调用失败了，到底是哪个服务导致的错误，我们需要能够快速定位到才能做到修复。
3. 用户反映，我们的系统很“慢”。如何知道究竟慢在何处？

若没有**调用链监控**，会存在如下问题：

1. 问题处理不及时，影响用户的体验
2. 不同应用的负责人不承认是自己的问题导致失败，容易出现“扯皮”
3. 服务之间的调用关系难以梳理，可能会存在很多错误的调用关系
4. 由于没有具体的数据，团队成员对自己的应用性能不在意

### 调用链监控的原理

> Google 发表过一篇论文，介绍过其生产环境中大规模分布式系统下的跟踪系统Dapper的设计和使用经验，主要是两个概念。

**Trace**:

- Trace 是指**一次请求调用的链路过程**，Trace ID 是指这次请求调用的 ID。
- 在一次请求中，会在网络的最开始生成一个全局唯一的用于标识此次请求的 Trace ID，这个 Trace ID 在这次请求调用过程中无论经过多少个节点都会保持不变，并且在随着每一层的调用不停的传递。
- 最终，可以通过 Trace ID 将这一次用户请求在系统中的路径全部串起来。

**Span**:

- Span 是指一个模块的调用过程，一般用 Span ID 来标识。
- 在一次请求的过程中会调用不同的节点/模块/服务，每一次调用都会生成一个新的  Span ID 来记录。
- 这样，就可以通过  Span ID 来定位当前请求在整个系统调用链中所处的位置，以及它的上下游节点分别是什么。

> 比如：
>
> 1. 前端浏览器发起请求到订单服务，订单服务会从数据库中查询出对应的订单数据。订单数据中包含了商品的ID，所以还需要查询商品信息。
> 2. 订单服务发起一笔调用，通过 RPC 的方式，远程调用商品服务的查询商品信息接口。
> 3. 订单服务组装数据，返回给前端。
>
> 查询订单数据和查询商品数据这两个过程，就分别是两个 Span，我们记为 SpanA 和 SpanB。SpanB 的parent 也就是父Span就是 SpanA。这两个Span都拥有同一个Trace Id：1

### CAT 概述

CAT 是一个**监控调用链系统**，是由大众点评开源的一款调用链监控系统，基于 JAVA 开发的。有一个**非常强大和丰富的可视化报表界面**。

**CAT 支持如下报表**：

| 报表名称         | 报表内容                                                     |
| ---------------- | ------------------------------------------------------------ |
| Transaction 报表 | 一段代码的运行时间、次数、比如 URL/cache/sql 执行次数相应时间，95/99线 |
| Event 报表       | 一段代码运行次数，比如出现一次异常                           |
| Problem 报表     | 根据 Transaction/Event 数据分析出系统可能出现的一次慢程序    |
| Heartbeat 报表   | JVM 状态信息                                                 |
| Business 报表    | 业务指标等，用户可以自己定制                                 |

### Transaction

**Transaction：适合记录跨越系统边界的程序访问行为，比如远程调用、数据库调用，也适合执行时间较长的业务逻辑监控，Transaction 用来记录一段代码的执行时间和次数**

**使用：**

```java
@RequestMapping("/api")
public String api(){
    Transaction t = Cat.newTransaction("URL", "pageName");
    try {
        // 设置执行时间1秒
        t.setDurationInMillis(1000);
        t.setTimestamp(System.currentTimeMillis());
        // 添加额外数据
        t.addData("content");
        // 设置状态，成功状态
        t.setStatus(Transaction.SUCCESS);
    } catch (Exception e) {
        // 设置状态，失败状态
        t.setStatus(e);
        Cat.logError(e);
    } finally {
        // 结束Transaction 
        t.complete();
    }
    return "api";
}
```

**API：**CAT 提供了一系列 API 来对 Transaction 进行修改。

- `addData`：添加额外的数据显示
- `setStatus`：设置状态，成功可以设置 SUCCESS，失败可以设置异常
- `setDurationInMillis`：设置执行耗时（毫秒）
- `setTimestamp`：设置执行时间
- `complete`：结束 Transaction 

### Event

**Event 用来记录一件事发生的次数，比如记录系统异常，它和 Transaction 相比缺少了时间的统计，开销比 Transaction 要小**

**Cat.logEvent**

```java
// 记录一个事件 
Cat.logEvent("URL.Server", "serverIp", Event.SUCCESS, "ip=${serverIp}");

// public static void logEvent(String type, String name){}
// public static void logEvent(String type, String name, String status, String nameValuePairs){}
```

**Cat.logError**

记录一个带有错误堆栈信息的 Error

- `public static void logError(String message, Throwable cause){}`
- `public static void logError(Throwable cause){}`

### Metric

**Metric 用于记录业务指标、指标可能包含对一个指标记录次数、记录平均值、记录总和，业务指标最低统计粒度为1分钟**

```java
// Counter，累加
Cat.logMetricForCount("metric.key");  // 调用一次+1
Cat.logMetricForCount("metric.key", 3);  // 调用一次+3

// Duration，累加取平均	
Cat.logMetricForDuration("metric.key", 5);
```

> 待完善...:stuck_out_tongue_winking_eye:

